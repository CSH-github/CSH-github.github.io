<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>



  <meta name="description" content="虽然之前对计算机视觉已经有所了解，但是总是没有系统的学习过计算机视觉，所以这次的暑假学习中，将《A Practical Introduction to COMPUTER VISION WITH OPENCV》这本书放到了第一个，学习了一个月之后，在这篇博客中归纳学习到的内容，内容根据书中的顺序进行安排。">
<meta name="keywords" content="计算机视觉">
<meta property="og:type" content="article">
<meta property="og:title" content="读书笔记 - 计算机视觉入门介绍">
<meta property="og:url" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="虽然之前对计算机视觉已经有所了解，但是总是没有系统的学习过计算机视觉，所以这次的暑假学习中，将《A Practical Introduction to COMPUTER VISION WITH OPENCV》这本书放到了第一个，学习了一个月之后，在这篇博客中归纳学习到的内容，内容根据书中的顺序进行安排。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/3.6.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/3.9.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/3.10.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.3.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.4.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.7.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.9.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.10.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.11.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.12.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.13.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.15.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.17.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.18.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.19.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.20.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.21.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.22.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.23.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.24.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.25.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.26.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.27.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.28.png">
<meta property="og:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/4.29.png">
<meta property="og:updated_time" content="2020-08-08T11:34:53.837Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="读书笔记 - 计算机视觉入门介绍">
<meta name="twitter:description" content="虽然之前对计算机视觉已经有所了解，但是总是没有系统的学习过计算机视觉，所以这次的暑假学习中，将《A Practical Introduction to COMPUTER VISION WITH OPENCV》这本书放到了第一个，学习了一个月之后，在这篇博客中归纳学习到的内容，内容根据书中的顺序进行安排。">
<meta name="twitter:image" content="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/3.6.png">





  
  
  <link rel="canonical" href="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>读书笔记 - 计算机视觉入门介绍 | Hexo</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/06/读书笔记-计算机视觉入门介绍/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">读书笔记 - 计算机视觉入门介绍

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-08-06 09:49:13" itemprop="dateCreated datePublished" datetime="2020-08-06T09:49:13+08:00">2020-08-06</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-08-08 19:34:53" itemprop="dateModified" datetime="2020-08-08T19:34:53+08:00">2020-08-08</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/读书笔记/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>虽然之前对计算机视觉已经有所了解，但是总是没有系统的学习过计算机视觉，所以这次的暑假学习中，将《A Practical Introduction to COMPUTER VISION WITH OPENCV》这本书放到了第一个，学习了一个月之后，在这篇博客中归纳学习到的内容，内容根据书中的顺序进行安排。</p>
<a id="more"></a>\

# Introduction

计算机视觉是由计算机进行的，自动分析图像和视频的过程。它最初根据人类的视觉系统而来，由于人类的视觉系统几乎是出于自然的条件反射，所以最开始人们也认为计算机视觉是一个直截了当的问题，但是事实上，无论是人类的视觉系统，还是计算机视觉的难题都比想象的要更加复杂。  

## A Difficult Problem 

对于计算机视觉的研究来说，首先要知道，这是一项很难的任务，对于计算机来说，图像就是一组值，计算机视觉就是要了解（understand）这一组值，而事实就是这一组值**很大**，很**复杂**，而且**时刻在变化**。  

## The Human Vision System

人们对于计算机视觉，首先想到的是，能否直接复制人类的视觉系统来解决这一问题，但问题是我们目前还不清楚人类的视觉系统大多数时刻在干些啥。  
首先对于眼睛来说，颜色视觉（6–700万个视锥细胞）集中在眼睛的中心，而其余的由1.2亿个视杆组成。所以在某种成都下，我们可以认为我们看到的，是一个连续的（continuous）图像（没有blind spot盲点），图像中各处都有颜色，但是目前我们也还不清楚这种印象如何在大脑中发生。  
尽管我们现在能根据电子信息的活动，判断大脑的各部位负责什么任务，但是这也不能为我们提供解决计算机视觉问题的算法或思路。

## Practical Applications of Computer Vision

计算机视觉在工业中有许多应用，特别是在生产线上自动检查制成品。 例如，它已用于质量检测，生物安全识别，车牌识别等。

## The Future of Computer Vision

尽管现在计算机视觉已经有很大的发展，但是仍有不足，比如现在仍然很难生产出可以在小路上行驶的可靠车辆，甚至同时也面临法律问题，如果车辆撞车，谁来负责？另外如果我们开发出一种医学成像系统来诊断癌症，而错误地没有诊断出病情时会发生什么？即使该系统可能比任何医师都更可靠，但是还是会进入法律的雷区。所以最简单的解决方案要么是仅解决非关键性问题，要么开发系统来作为当前人类专家的助手，而不是替代人类专家。另外有可能遇到的问题比如，在某些国家/地区，摄像机的安装和使用被视为侵犯了基本隐私权。  
所以在未来，我们希望计算机视觉能在更自由更复杂的环境中发挥作用，比如自动驾驶，协助抓贼等等。  
而计算机视觉的最终目的，是模仿人类视觉的能力，并将这些能力提供给类人机器人（和其他）机器人设备。虽然我们都有自己的良好的视觉系统，但是我们仍然希望自动的实现任何的计算机视觉任务。

# Images

计算机视觉最重要的因素之一是图像，因为它为计算机提供了场景的视觉上的表示，以便计算机后续处理来突出感兴趣的特征，最后提取出信息。

## Cameras

标准的相机由一个感光图像平面（photosensitive image plane）（可感应落在平面上的光量），一个防止杂散光掉落到感光图像平面上的外壳（housing），以及一个镜头罩（lens）组成，镜头允许部分光落图像平面上（镜头能通过控制透镜，将光线聚焦到图像平面上）。

### The Simple Pinhole Camera Model

最简单但合理的模型是针孔照相机模型，如图2.1所示，模型中镜头化简为针孔。该模型是大多数实际成像系统的简化，因为实际系统的各个部分都会在生成的图像中引入失真（变形）。其中从3D世界中的点（x，y，z）到图像平面上的点（i，j）的映射可以建模为：
$$
\left[\begin{array}{c}
i . w \\
j . w \\
w
\end{array}\right]=\left[\begin{array}{ccc}
f_{i} & 0 & c_{i} \\
0 & f_{j} & c_{j} \\
0 & 0 & 1
\end{array}\right]\left[\begin{array}{l}
x \\
y \\
z
\end{array}\right]
$$
其中$w$为尺度因子，$f_i$和$f_j$是相机的焦距和像素大小的结合，$（c_i，c_j）$是与图像平面垂直且经过针孔的线与图片平面相交的点的坐标。

![图2.1](./读书笔记-计算机视觉入门介绍/2.1.png)

## Images

图像是由传感器捕捉到的画面（通常是3D场景的2D投影）。而且图像可以看做是图像平面上的，关于两个坐标（（i，y）或（column，row））的连续函数，但是如果要在电脑上处理这样的图像，它必须经过一下操作：
1. 采样。从传感器信息中采样，并输入一个M×N的矩阵中。
2. 量化。矩阵中的每个元素都需要设置成整数，所以连续空间被分成一些间隔（通常为256）。

### Sampling

图像本来应该是连续的，尤其是对于人眼来说，但是对于电脑来说，它会将**连续图像采样到离散的元素**中来创建数字图像，以便电脑处理。而数字图像的传感器由2D的光敏元件阵列组成，且每个元件（像素点/采样点/图像点）只在**一定的固定区域上是光敏的**，点之间的边缘区域则不是光敏的，所以传感器会丢失掉这部分的信息（比如远处的物体恰好落在缝隙）。但采样更重要的问题是，该像素代表了离散区域的平均值（亮度/色度），这在现实世界中，可以从单个物体中折射过来，也可能是多个物体反射光的总和。  
显而易见，像素点的数量会影响分辨率，见图2.2所示，从而限制图像中能识别出的对象，但是过多的数量又会带来超过需求的细节，使处理变的困难，因此需要权衡。

![图2.2](./读书笔记-计算机视觉入门介绍/2.2.png)

### Quantisation

函数$f(x，y)$表示了每个像素的亮度，亮度本应该是连续的，但是我们需要整数值，因此需要离散的表示，通常每个通道的亮度的级别有$k=2^{b}$个，其中b表示比特数（通常为8），b越大，储存图像所需的内存越大，但是越少，信息会丢失，所以实际上取决于储存的图像的目的，通常需要比预期更高的量化级别。

## Colour Images

灰度（单色）图像只有一个通道，只能表示每个点的亮度，而彩色（多光谱）图像具有多个通道，能同时表示场景中的亮度和色度（颜色信息）。 因此，同样的采样和量化下，彩色图像比灰度图像更大，更复杂。而我们总是需要利用彩色图像的多个通道，所以我们必须以某种方式决定如何处理每个信息通道。（也有许多图像处理是专门为灰度图像开发的。）  
事实上是，由于人类也能理解灰度图像，且灰度图像更小更简单，所以计算机视觉多年来都一直基于灰度图像。但是颜色确实能通过更有用的信息帮助完成图像分割，物体分类等任务。  
另外人类对于波长为400nm~700nm之间的光敏感，所以大多数相机的传感器被设计为对这些波长敏感，另外彩色图像通常使用三通道的色彩空间进行表示，如下所示。

### Red–Green–Blue (RGB) Images

彩色图像的最常见表示形式是使用三个通道，它们大致对应于红色（700 nm），绿色（546.1 nm）和蓝色（435.8nm）波长。这意味着照相机中的感光元件对以这些颜色为中心的波长才具有光谱敏感性（如图2.6）。

![图2.6](./读书笔记-计算机视觉入门介绍/2.6.png)

值得注意的是，由于量化，尽管该色彩空间有1680万多种（256\*256\*256），有些颜色仍无法表示。  
RGB颜色信息可以转换为灰度图：
$$
Y=0.299 R+0.587 G+0.114 B
$$
另外，感光平面上的一个位置只有一个元件，一个元件只对一种波长有光谱敏感性，所以对不同波长感光的元件并非位于同一位置，而是以规则模式显示，如图2.7所示，而RGB值则是以某种方式，从这些感应值内插得到。这意味着接收到的图像甚至不是连续图像的正确采样（错位），而是从传感器元件接收到的数据中插入得到的。

![图2.7](./读书笔记-计算机视觉入门介绍/2.7.png)

### Cyan–Magenta–Yellow (CMY) Images

CMY模型基于二次色（secondary colour，通过混合两个主次色得来）（RGB是主次色），其中C，M和Y的值，通过从纯白色中减去R，G，B的值得来。 所以，它通常在以白色为起点的打印机中用作颜色模型。
$$
C=255-R, \quad M=255-G, \quad Y=255-B
$$

### YUV Images

YUV颜色模型用于模拟电视信号（PAL，NTSC…），它由亮度（Y）以及两个颜色分量组成：蓝色减去亮度（U）和红色减去亮度（V）。 从RGB的转换方程如下：

* $Y=0.299 R+0.587 G+0.114 B$
* $U=0.492^{*}(B-Y)$
* $V=0.492^{*}(R-Y)$
人类的视觉系统对亮度比对色度更加敏感，而电视信号的编码需要以减少传输的数据量为目的，所以会用到这个色彩空间。

### Hue Luminance Saturation (HLS) Images

HLS模型在计算机视觉中经常使用，因为它除了将亮度和色度分开外，还将色度分为色相和饱和度，所以能够更加贴切的描述（例如深蓝色，浅红色等）。通常来说，亮度在0到1之间，色相描述了颜色，在0到360°之间，饱和度S是颜色的强度或纯度，在0到1之间。但在实际实现中，这些量会映射到到0到25​​5的范围（OpenCV内，色相值的范围是0到179）。直观的色彩空间的显示如图2.10。

![图2.10](./读书笔记-计算机视觉入门介绍/2.10.png)

从图2.10中可以明显发现，色相轴的圆形性质，这意味着最小（0）和最大（179）的色相值仅相差1，所以它们在颜色上没有太大区别，都对应于红色像素，但是单单看色相图，一个是黑色一个是白色，这意味着，如果要处理色相通道，则必须格外小心。例如，如果0、178、1、177和179的平均色相值应为179，而不是107。  
另外，RGB和HLS之间的转换方程如下（RGB都被规范化到0.0和1.0之间）：
$$
\begin{array}{l}
L=\operatorname{Max}(R, G, B)+\operatorname{Min}(R, G, B) / 2 \\
S=\left\{\begin{array}{ll}
\operatorname{Max}(R, G, B)-\operatorname{Min}(R, G, B) / \operatorname{Max}(R, G, B)+\operatorname{Min}(R, G, B) & \text { if } L<0.5 60="" \\="" \operatorname{max}(r,="" g,="" b)-\operatorname{min}(r,="" b)="" 2-(\operatorname{max}(r,="" b)+\operatorname{min}(r,="" b))="" &="" \text="" {="" if="" }="" l="" \geq="" 0.5="" \end{array}\right.="" h="\left\{\begin{array}{ll}" .(g-b)="" s="" r="\operatorname{Max}(R," 120+60="" .(b-r)="" g="\operatorname{Max}(R," 240+60="" .(r-g)="" b="\operatorname{Max}(R," \end{array}="" $$="" 根据上面的公式，l和s值将在0.0到1.0之间，h值应在0.0到360.0之间。="" ###="" other="" colour="" spaces="" opencv提供对其他六个颜色空间的支持（就转换功能而言）：="" 1.="" hsv。="" 2.="" ycrcb="" 缩放了的yuv，用于图像和视频压缩。="" 3.="" cie="" xyz="" 标准的参考色彩空间，其中通道响应类似于人眼中不同的圆锥响应。="" 4.="" $\mathrm{l}^{*}="" \mathrm{u}^{*}="" \mathrm{v}^{*}$="" cie定义的另一种标准颜色空间，旨在提供一种感知上统一的颜色空间，其中颜色之间的差异与我们感知到的差异成比例。="" $\mathrm{l}^{*}$是亮度的量度，$\mathrm{u}^{*}$和$\mathrm{v}^{*}$是色度值。="" 5.="" \mathrm{a}^{*}="" \mathrm{b}^{*}$="" 与设备无关的色彩空间，其中包括人类可以感知的所有颜色。="" 6.="" 拜耳（bayer）是ccd传感器中广泛使用的模式，如果我们有原始传感器数据（即尚未插值），则使用拜耳模式。="" some="" applications="" 在某些应用中，我们需要确定哪些像素代表特定颜色。例如，要查找路标，我们会对红色，黄色，蓝色，黑色和白色特别感兴趣。我们可以通过创建用于识别特定颜色的简单公式来识别特定颜色，如以下的介绍，但应注意的是，标准本身真的太粗糙了，很容易失效，也因为该标准不是基于足够数量的图像，所以实际上应该以更严格的方式进行处理。="" ####="" skin="" detection="" 简单的通过以下公式：="" (saturation="">=0.2 ) AND (0.5<\text {="" luminance="" }="" \text="" saturation="" }<3.0="" )="" and="" (hue="" <="28^{\circ}" or="" hue="">=330^{\circ} )
$$
将识别许多皮肤像素。 但是，很明显，这也会识别其他像素。

#### Red Eye Detection

同样通过以下公式：
$$
(Luminance >=0.25 ) AND (Saturation >=0.4 ) AND \left.\qquad(0.5<\text {="" luminance="" saturation="" }<1.5)="" \text="" and="" (hue="" }<="14^{\circ}" or="" hue="" }="">=324^{\circ}\right)
$$
识别红眼像素，通过实验可以确定，这还需加以改进，但是它是识别红眼的良好起点。

## Noise

图像通常会受到某种程度的噪声（噪声可以是任何会降低图像质量的因素）的影响，且这种噪声会对处理过程产生影响。总的来说，噪声能来源于环境，成像设备，电气干扰，数字化过程等。而对于噪声，我们需要能够测量它，并以某种方式对它进行校正。  
首先对噪声大小的衡量标准，我们使用信噪比（the signal to noise ratio）来衡量。对于一幅图像$f(i, j)$，信噪比定义为：
$$
S / \text {Nratio}=\Sigma_{(i, j)} f^{2}(i, j) / \Sigma_{(i, j)} v^{2}(i, j)
$$
其中$v(i, j)$代表噪声。

### Types of Noise

两种最常见的噪声类型是高斯噪声和椒盐噪声。

#### Gaussian Noise

高斯噪声能很好的拟合许多的实际噪声。其中，噪声$v(i, j)$被建模为一个平均值为$\mu$（通常为0），标准差为$\sigma$的高斯分布，如图2.14所示。

![图2.14](./读书笔记-计算机视觉入门介绍/2.14.png)

#### Salt and Pepper Noise

椒盐噪声是脉冲噪声的一种，通过对单个像素的损坏，使其亮度与周围区域的亮度差异很大，其中饱和脉冲噪声会影响图像（即，纯白色和黑色像素会破坏图像），如图2.15所示。

![图2.15](./读书笔记-计算机视觉入门介绍/2.15.png)

### Noise Models

噪声必须以某种方式与图像数据结合在一起，根据噪声是与数据无关还是与数据有关可以将之分为两类。

#### Additive Noise 

这类噪声模型用于数据独立的噪声（噪声量与图像数据本身无关），其中附加噪声模型能表示为：
$$
f(i, j)=g(i, j)+v(i, j)
$$
其中$g(i, j)$是原始图像，$v(i, j)$是噪声，而$f(i, j)$是实际图像。

#### Multiplicative Noise

这类噪声模型用于数据依赖的噪声（噪声量与图像数据本身有关），其中乘法噪声模型能表示为：
$$
f(i, j)=g(i, j)+g(i, j) \cdot v(i, j)
$$
其中$g(i, j)$是原始图像，$v(i, j)$是噪声，而$f(i, j)$是实际图像。

### Noise Generation

为了评估消除噪声的算法，我们经常需要先模拟噪声，以便可以消除/减少噪声后，评估算法成功的程度。首先假设我们生成的噪声具有高斯分布，均值为0，标准差为$\sigma$。  
我们首先确定，能从最大可能的负变化到最大可能的正变化（通常k = -255..255）之间的所有可能噪声值的概率分布$p(k)$和累积概率分布$p_cum(k)$。
$$
\begin{aligned}
p(k) &=e^{-k^{2} / 2 \sigma^{2}} / \sigma \sqrt{2 \pi} \quad k=-(G-1), \ldots,-1,0,1, \ldots, G-1 \\
p_{\mathrm{cum}}(k) &=p_{\mathrm{cum}}(k-1)+p(k) \\
p_{\mathrm{cum}}(-(G-1)) &=p(-(G-1))
\end{aligned}
$$
累积概率分布确定后，我们就能计算图像中，每个像素的噪声值了。  
对于每个像素$(x，y)$，可以设置其值为：
$$
f^{*}(i, j)=g(i, j)+\operatorname{argmin}_{\mathrm{k}}\left(\operatorname{rand} 0-p_{\mathrm{cum}}[k]\right)
$$
其中：
$$
\begin{array}{ll}
f^{\prime}(x, y)=0 & \text { if } f^{*}(x, y)<0 \\="" f^{\prime}(x,="" y)="G-1" &="" \text="" {="" if="" }="" f^{*}(x,="">G-1 \\
f^{\prime}(x, y)=f^{*}(x, y) & \text { otherwise }
\end{array}
$$
注意，argmin函数给出最小值的索引，在这种情况下，将在累积分布内选择值最接近随机数的k。另外，截断（为确保值保持在0到255之间）其实会稍微改变噪声的高斯性质。

### Noise Evaluation

噪声的评估可以主观或客观地进行。 在主观评估中，将图像显示给观察者，观察者根据一系列标准对其进行评估并给出评分。但是在客观评估中，给定图像$f(i, j)$和已知参考图像$g(i, j)$，我们可以对它们之间差异进行度量，例如：
$$
\begin{array}{l}
\text { Mean Quadratic Difference }=\sum \sum(g(i, j)-f(i, j))^{2} \\
\text { Mean Absolute Difference }=\sum \sum|g(i, j)-f(i, j)| \\
\text { Or we can compute the signal to noise ratio assuming} v(i, j)=f(i, j)-g(i, j)
\end{array} 
$$
显然，这种客观评估需要我们事先知道原始图像或添加的噪声。因此，实验中经常人为地添加噪声，以检验现有技术在去除噪声方面的表现如何。

## Smoothing

消除噪声的方法有很多种，但是由于技术原理的不同或图像数据性质的不同，在不同情况下应该使用不同的技术。  
其中，减少噪声最常用的方法是线性平滑变换，其中的计算可以表示为线性和，但是这样的噪声会导致锐边模糊，因此有些方法提出了非线性变换（不能表示为简单的线性和，逻辑操作等）。  
注意这些技术面对像是大斑点或者后条纹，都无法起作用，这时需要用到的是图像恢复技术。

### Image Averaging

如果对完全相同场景，存在多个图像，则将它们进行平均处理，就可以减少噪声。比如现有n张图像，其平均值为：
$$
f^{\prime}(i, j)=\frac{1}{n} \sum_{k=1 . . n} f_{k}(i, j)=\frac{1}{n} \sum_{k=1 . . n} g_{k}(i, j)+v_{k}(i, j)
$$
这种消除噪声的算法假设噪声是数据独立的。同样也假设：

* 所有图像的原始图像$g_{\mathrm{k}}(i, j)$是相同的（即场景和摄像机是静态的）。
* 每个图像中的噪声$v_{\mathrm{k}}(i, j)$之间存在统计独立性。
* 噪声$v_{\mathrm{k}}(i, j)$具有高斯分布，且均值为0和标准差为𝜎。

如果以上假设成立，那么图像平均之后，将保持高斯性质，但标准偏差将减小$\sqrt{n}$倍，如图2.16所示。

![图2.16](./读书笔记-计算机视觉入门介绍/2.16.png)

由以上假设可知，该方法不适用于椒盐噪声，且当场景非静态时，将引入模糊。

### Local Averaging and Gaussian Smoothing

如果只有一个图像可用，则仍然可以执行平均，但不是全局，而是对图像中的每个点，计算以当前点为中心的像素块（而不是使用多个图像中的对应点）的平均值，最简单的比如3×3。  
若每个点都均等权重，该技术称为局部平均（local averaging），也就是**加入模糊效果**，滤波器的蒙版越大，效果越明显。但是也可以更改权重，以便为更接近当前点的点赋予更高的权重，其中非常常见的加权方法是由高斯分布定义的。 例如，以下所示：
$$
h_{1}=\frac{1}{9}\left[\begin{array}{lll}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{array}\right] \quad h_{2}=\frac{1}{10}\left[\begin{array}{lll}
1 & 1 & 1 \\
1 & 2 & 1 \\
1 & 1 & 1
\end{array}\right] \quad h_{3}=\frac{1}{16}\left[\begin{array}{lll}
1 & 2 & 1 \\
2 & 4 & 2 \\
1 & 2 & 1
\end{array}\right]
$$
$h_1$是一个3×3的局部平均滤波器，$h_2$和$h_3$都是3×3的高斯平滑滤波器，但前者的$\Sigma$更小。

很明显，局部像素进行平均时，会引入模糊从而降低可见的（高斯）噪声，但是它也会对边缘（灰度或颜色变化很大）产生影响，反而使图像更模糊，反而更难处理，但有时这都无可厚非，都是需要平衡的点。  
值得注意的是，对于椒盐噪声，平均后，噪声也会再次平滑到图像中，局部平均滤波器并不适用于此类噪声。  
另外，对于这种平均操作，通常使用卷积技术来执行，将掩码（通常为正方形且以当前点为中心）与所有可能位置进行卷积：
$$
f^{\prime}(i, j)=\sum_{\mathrm{m}} \sum_{\mathrm{n}} f(i, j) \cdot h(i-m, j-n)
$$

### Rotating Mask

旋转遮罩是一种非线性算子，它首先分别在九个预设的包含当前点的mask内进行计算，选出其中最均匀的（即自相似的）mask，然后在mask内，应用平均滤波器。其中所有的mask如图2.19所示，其形状和大小可以变化。

![图2.19](./读书笔记-计算机视觉入门介绍/2.19.png)

对于每一个mask，我们计算与mask中的点相对应的点的局部平均值（色散）来衡量其自似性，然后选择色散最小的mask来进行平均化操作。这样的目的是减少当前点的噪声，让当前点与来自相同物理刺激（例如表面或物体）的其他类似点取平均值。  
该技术可以迭代着来使用，直到没有变化或变化很小。掩码越大，收敛越快，但尽管该技术要慢得多，但它能同时**抑制噪声和锐化图像边缘**。其中色散可通过计算每个点的平方差的均值得来：
$$
D=\frac{1}{n} \sum_{(i, j) \in M a s k}\left(f(i, j)-1 / n \sum_{\left(i^{\prime}, j^{\prime}\right) \in \text { Mask }} f\left(i^{\prime}, j^{\prime}\right)\right)^{2}
$$
化简为；
$$
D=\frac{1}{n}\left(\sum_{(i, j) \in \text { Mask }} f(i, j)^{2}-1 / n\left(\sum_{\left(i^{\prime}, j^{\prime}\right) \in \text { Mask }} f\left(i^{\prime}, j^{\prime}\right)\right)^{2}\right)
$$
化简后，计算cost显着降低。  
另外，该技术可以应用于，具有椒盐噪声的图像，但是会导致不良效果，尤其是当噪声存在于物体边缘时。

### Median Filter

另一种非线性平滑操作是将每个像素替换为，以该像素为中心的小区域（例如3x3）中的像素中位值。例如，3x3区域包含像素值（25 21 23 25 18 18 255 30 13 22），排序后为（13 18 22 21 23 25 25 30 255），其中位数为23，而均值为48。可见该技术非常擅长处理噪声，且该技术不会使边缘模糊太多，所以可迭代应用。而实际上，中值滤波与旋转mask的效果非常相似。如图2.17和2.18所示。

![图2.17](./读书笔记-计算机视觉入门介绍/2.17.png)

![图2.18](./读书笔记-计算机视觉入门介绍/2.18.png)

虽然也可将其与上一个，在非矩形区域计算的技术结合，但是它还是会损坏细线和角，而且其时间复杂度为$O\left(k^{2} \log k\right)$，所以计算上也很昂贵。拓展的优化技术可看[Median Filtering in Constant Time by Perreault](http://vision.gel.ulaval.ca/~perreaul/publications/Id699_2007.pdf)

# Histograms

一个图像的直方图是对该图像的抽象描述，其中包含了各个图像值（亮度/强度）的频率。

## 1D Histograms

对于灰度图像，其中灰度强度有256种（0-255），而每个强度对应的值，表示图像中属于该灰度的，有多少个像素。如图3.1所示。

![图3.1](./读书笔记-计算机视觉入门介绍/3.1.png)

图像的直方图中包含了该图像的全局信息，并且该信息完全独立于场景中各个对象的位置和方向，所以同一直方图对应的图像不是唯一的，许多非常不同的图像可能具有相似（甚至相同）的直方图。另外，直方图中得出的信息（例如平均强度及其标准偏差）可用于执行分类。

### Histogram Smoothing

直方图中，无论是全局还是局部的最大值和最小值都能提供有用的信息，但是局部的极值太多了。为了减少此数字，可以对直方图进行平滑处理。首先创建一个新的直方图，其中每个值，都是以原始直方图中的相应值为中心的多个值的平均值。此过程通常称为过滤。如图3.2。

![图3.2](./读书笔记-计算机视觉入门介绍/3.2.png)

### Colour Histograms

对于彩色图像这样的多通道图像来说，通常为每个通道独立确定直方图，如图3.3，图3.4。

![图3.3](./读书笔记-计算机视觉入门介绍/3.3.png)

![图3.4](./读书笔记-计算机视觉入门介绍/3.4.png)

由上可知，不同的颜色模型，直方图也有很大的区别，进而对其有用性产生巨大影响。比如图3.4中可以直接发现，红色和绿色很显著。

## 3D Histograms

对于色彩图像的直方图处理，若是均独立处理，则不会实现最佳的颜色分割。比如相似颜色的点都具有较高的饱和度和色相值，这时需要更好的分割，则需要用到3D直方图，如图3.5。

![图3.5](./读书笔记-计算机视觉入门介绍/3.5.png)

其中，(0,0,0)点显示在左下角的顶层。绿轴从顶层的左下角到右下角，蓝轴从顶层的左下角到左上角，红轴从顶层的左下角到最底层的左下角。每个单元内显示的灰度强度表示每个单元中的相对像素数（黑色= 0，白色=最大）。  
另外就是直方图中的**单元数的设置**。如果我们假设每个通道8位，则直方图中将有近1,680万个单元，这作为图像中信息的摘要来说太多了，所以我们需要减少了直方图的量化。比如图3.5中，每个通道只有2位，所以直方图中只有64个单元。  
OpenCV中的代码可写为：
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MatND histogram;</span><br><span class="line"><span class="keyword">int</span> channel_numbers[] = &#123; <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span> &#125;;</span><br><span class="line"><span class="keyword">int</span> * number_bins = <span class="keyword">new</span> <span class="keyword">int</span>[image.channels()]; </span><br><span class="line"><span class="keyword">for</span> (ch=<span class="number">0</span>; ch &lt; image.channels(); ch++)</span><br><span class="line">	number_bins[ch] = <span class="number">4</span>;</span><br><span class="line"><span class="keyword">float</span> ch_range[] = &#123; <span class="number">0.0</span>, <span class="number">255.0</span> &#125;;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">float</span> * channel_ranges[] = &#123;ch_range,ch_range,ch_range&#125;;</span><br><span class="line">calcHist( &amp;image, <span class="number">1</span>, channel_numbers, Mat(), histogram, image.channels(), a_number_bins, channel_ranges );</span><br></pre></td></tr></table></figure>
<h2 id="Histogram-Image-Equalisation"><a href="#Histogram-Image-Equalisation" class="headerlink" title="Histogram/Image Equalisation"></a>Histogram/Image Equalisation</h2><p>在最佳观看条件下，人类可以区分700到900种灰度，但是在图像的非常黑或非常亮的区域，just noticeable difference（JND）将大大降低，人类也将很难解读图像，然而，很明显，人类更容易区分较大的差异，因此，如果改善图像中的灰度分布，这将有助于人类观察者的理解。<br>而改善图像中的灰度分布的一种技术是<strong>直方图均衡化</strong>，它通过在图像中均匀分布灰度，使生成的直方图变得平坦（即各个灰度具有完全相同的点数），但绝对的平坦是不可能的，实际情况是，有些像素没有值，而有较高值的灰度图散落在直方图中。见图3.6。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/3.6.png" alt="图3.6"></p>
<p>另外，对于彩色图像时，我们通常仅均衡亮度通道的直方图，以免颜色失真。</p>
<h2 id="Histogram-Comparison"><a href="#Histogram-Comparison" class="headerlink" title="Histogram Comparison"></a>Histogram Comparison</h2><p>大多数图像搜索引擎都提供了，检索与给定图像相似或包含特定内容的图像的功能，这大多数情况下是通过使用与图像关联的元数据标签实现的，但是通过分析图像中的颜色分布，也可以为该过程提供帮助，比如分析比较直方图。<br>用于比较直方图的指标如：</p>
<ul>
<li>$D_{\text {Correlation }}\left(h_{1}, h_{2}\right)=\frac{\sum_{i}\left(h_{1}(i)-\overline{h_{1}}\right)\left(h_{2}(i)-\overline{h_{2}}\right)}{\sqrt{\sum_{i}\left(h_{1}(i)-\overline{h_{1}}\right)^{2} \sum_{i}\left(h_{2}(i)-\overline{h_{2}}\right)^{2}}}$</li>
<li>$D_{\text {Chi }-\text { Square }}\left(h_{1}, h_{2}\right)=\sum_{i} \frac{\left(h_{1}(i)-h_{2}(i)\right)^{2}}{\left(h_{1}(i)+h_{2}(i)\right)}$</li>
<li>$D_{\text {Intersection }}\left(h_{1}, h_{2}\right)=\sum_{i} \min \left(h_{1}(i), h_{2}(i)\right)$</li>
<li>$D_{\text {Bhattacharyya }}\left(h_{1}, h_{2}\right)=\sqrt{1-\frac{1}{\sqrt{\overline{h_{1}} \overline{h_{2}} N^{2}}} \sum_{i} \sqrt{h_{1}(i) \cdot h_{2}(i)}}$<br>其中:</li>
<li>$N$ 是直方图中的格子数(bin)</li>
<li>$\overline{h_{k}}=\Sigma_{i}\left(h_{k}(i)\right) / N$</li>
</ul>
<p>另外，也可以使用<strong>Earth Mover’s Distance</strong>，来确定将一种分布（在这种情况下为直方图）转换为另一种分布的最低路线的距离。通过迭代可以得出结果：</p>
<script type="math/tex; mode=display">
\begin{array}{c}
E M D(-1)=0 \\
E M D(i)=h_{1}(i)+E M D(i-1)-h_{2}(i)
\end{array}</script><p>最后的距离就可写为：</p>
<script type="math/tex; mode=display">
\sum_{i}|E M D(i)|</script><p>这也可以用在颜色直方图中。</p>
<h2 id="Back-projection"><a href="#Back-projection" class="headerlink" title="Back-projection"></a>Back-projection</h2><p>上一章介绍了一些非常简单的方法来选择图像中的特定颜色。这些方法在定义它们的颜色空间中选择了相当粗糙的子空间。解决此问题的更好方法如：</p>
<ol>
<li>获取要选择的颜色的代表性样本集（类似颜色的照片切片）。</li>
<li>根据这些样本创建直方图。</li>
<li>将直方图标准化，使其最大值为1.0，这样就可以将直方图的值视为概率（即，具有相应颜色的像素来自样本集的概率）。</li>
<li>将归一化后的直方图反向投影到，需要计算图像中的每个像素与样本集的像素的相似度的图像中，也就是得出了一个概率图$p$，其中$p(i, j)$表示$f(i, j)$像素和对应样本集之间的相似性，即$p(i, j)=h(f(i, j)))$。</li>
</ol>
<h2 id="k-means-Clustering"><a href="#k-means-Clustering" class="headerlink" title="k-means Clustering"></a>k-means Clustering</h2><p>颜色的一个主要问题是它种类太多了（例如8位RGB空间就有1680万种颜色），所以通常会希望减少此数字，来更真实的压缩图像，或者表示某人穿着的衣服的颜色。为了实现这种效果，一种常用的技术是在3D颜色空间中进行聚类（例如，参见图3.9中使用的<strong>原始的k均值聚类算法</strong>）。  </p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/3.9.png" alt="图3.9"></p>
<p>该算法的目的，是找出k个示例（即特定颜色）来最好地表示图像中的所有颜色，这个k是超参数，是预先指定的。图像中的每个像素的颜色称为pattern、图案。而与特定的exemplar、范例（k个示例之一）关联的一组pattern，称为一簇。操作如下：</p>
<ul>
<li>起始exemplar可以来源于：<ul>
<li>随意选择</li>
<li>选择最开始的k个pattern</li>
<li>均匀的分布</li>
</ul>
</li>
<li>第一轮：对于所有pattern，将其分配给最近的exemplar。在每个新pattern都被关联之后，计算与exemplar相关联的所有pattern的重心，并将之作为新的exemplar。</li>
<li>第二遍：使用第一遍得到的新的exemplar，然后给所有pattern根据距离重新分配给exemplar（这些分配可能与上次不同）。 </li>
</ul>
<p>对k聚类算法的简单的一维展示如图3.10所示：</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/3.10.png" alt="图3.10"></p>
<p>注意，由于每次起始样本的选择都是随机的，所有该<strong>算法是不确定</strong>的，所有每次执行都会有不同的结果。另外对于一个区域，用多少种颜色来表示并不容易，比如在图3.9中，只有右侧的图像才能真实地<strong>再现</strong>每个斯诺克球的颜色，所以如何才能确定，用多少个颜色（k）再现区域会更加合适呢？<br>一种方法是看哪个聚类数的输出结果具有最高的置信度，置信度可以使用诸如Davies-Bouldin指数之类的指标：</p>
<script type="math/tex; mode=display">
\mathrm{DB}=1 / \mathrm{k} \sum_{1 . . \mathrm{k}} \max _{i \neq j}\left(\left(\Delta_{\mathrm{i}}+\Delta_{\mathrm{j}}\right) / \delta_{\mathrm{i} . \mathrm{j}}\right)</script><p>它考虑了k个聚类，并对聚类之间的分离度求和。具体来说，对于每个簇，都使用以上公式，找到与之最不分离的另一个簇。以上公式对于任何两个簇，分别计算两个簇到各自的簇中心的平均距离之和（Δi +Δj），再除以簇之间的距离，得到分离度。尽管此指标是簇中最常用的指标之一，但由于它没有考虑簇的大小，因此在簇的大小不一的情况下效果不佳。</p>
<p>总的来说，k均值聚类是无监督学习的一个示例，即从现有的数据中学会了划分方式。其中非监督学习是指学习过程中，不会收到分类是否正确的反馈的学习，它必须基于<strong>输入数据的内部规律</strong>，来让相似的事件/像素点/物体，以相同方式被分类。</p>
<h1 id="Binary-Vision"><a href="#Binary-Vision" class="headerlink" title="Binary Vision"></a>Binary Vision</h1><p>灰度图像的每个像素通常有8位，尽管在某些方面，它处理起来会比彩色图像更容易，但是存在一种比灰度图像更简单的图像形式（即二进制图像）。实际上，计算机视觉已经有很大一部分的实际应用基于二元图像。  </p>
<h2 id="Thresholding"><a href="#Thresholding" class="headerlink" title="Thresholding"></a>Thresholding</h2><p>通过对灰度图像进行阈值处理，能得到二元图像。算法很简单：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\text{For all pixe} & \text{ls} (i, j) \\
f^{\prime}(i, j) &=1 \text { where } f(i, j)>=T \\
&=0 \text { where } f(i, j)<T
\end{aligned}</script><p>二元图像的灰度值并非二进制的0和1，而通常使用灰度值0和255代替，所以可以使用8位的格式表示结果图像，进而可以用与原始灰度图像相同的方式来显示和处理。<br>虽然可以逐元素判断其值是否超过阈值，但最有效的方法（通常可以在硬件中完成）是使用查找表。</p>
<script type="math/tex; mode=display">
\begin{aligned}
\text{For all grey lev} &\text{els } k = 0 \text{. . .} 255 \\
\operatorname{LUT}(k) &=1 \text { where } k>=T \\
&=0 \text { where } k<T \\
\text{For all pixels } (i&, j) \\
g(i, j) = &\operatorname{LUT}(f(i, j))
\end{aligned}</script><p>通常使用阈值操作以便将某些感兴趣的对象与背景分离，且通常将感兴趣的部分用1（或255）表示，但有时需要反转二进制图像才能如此。</p>
<h3 id="Thresholding-Problems"><a href="#Thresholding-Problems" class="headerlink" title="Thresholding Problems"></a>Thresholding Problems</h3><p>若要使用阈值技术，首先，要分离开的前景和背景必须是不同的。如果它们没有区别，将很难（甚至不可能）使用阈值技术来准确地对其进行细分。但也有许多技术（比如自适应阈值）来尝试处理前景和背景的区别不明确的情况，和许多技术（例如腐蚀，膨胀，打开，关闭） 来改善分割不完美的二值图像。</p>
<h2 id="Threshold-Detection-Methods"><a href="#Threshold-Detection-Methods" class="headerlink" title="Threshold Detection Methods"></a>Threshold Detection Methods</h2><p>即使在某些工业化的密闭场景，随着时间的推移，其照明条件也会发生变化，其光源也会随着时间逐渐变弱，若只是凭借一开始手动设置的阈值，就可能会引起问题。因此，需要一种机制来自动的确定阈值。<br>在以下内容中，我们假设有一个灰度图像$f(i, j)$，它的直方图为$h(g)=\sum_{i, j}\left[\begin{array}{l}1 f(i, j)=g \\ 0 \text { otherwise }\end{array}\right.$，再将之转换为概率分布$p(g)=h(g) / \sum_{g} h(g)$。</p>
<h3 id="Bimodal-Histogram-Analysis"><a href="#Bimodal-Histogram-Analysis" class="headerlink" title="Bimodal Histogram Analysis"></a>Bimodal Histogram Analysis</h3><p>图像的阈值可以通过分析其直方图而来。现在我们假设，图像的背景主要集中于一个灰度值，而前景主要集中于另一个灰度值，那进而可以假设直方图是双峰的（即具有两个主峰）。然后，要计算阈值，我们可以简单地寻找anti-mode、反模式（峰值之间的最小值）。  </p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.3.png" alt="图4.3"></p>
<p>但是，如图4.3所示，虽然直方图整体上是双峰的，但它同时也存在许多局部的最大值和最小值，所以要找到反模式其实并不容易。一般有以下几种方法来解决此问题时：</p>
<ul>
<li>首先使直方图平滑（来抑制噪声的峰值）</li>
<li>使用可变的步长来找反模式（而不是将每个直方图的每个模式都考虑到）</li>
<li>忽略梯度高的点（因为这些点代表了边界），从而更好的分割直方图的两种模式</li>
<li>仅仅对边界点绘制直方图，然后直接获取直方图的模式，即为反模式。</li>
</ul>
<p>然而，以上这些方法有时会造成反模式的偏移，从而产生不好的阈值。所以接下来介绍其他基于直方图的更为可靠的方法。</p>
<h3 id="Optimal-Thresholding"><a href="#Optimal-Thresholding" class="headerlink" title="Optimal Thresholding"></a>Optimal Thresholding</h3><p>以上的技术，适用于模式合理地分开并噪声不太大的情况，但是当模式之间的距离越来越近时，首先反模式就不再是最佳解决方案。如图4.4中的两个正态分布及其求和所示。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.4.png" alt="图4.4"></p>
<p>其最佳阈值应该是两个正态分布相交的位置（左侧垂直线），但这时总分布的反模式位于右侧（右侧垂直线）。<br>综上所述，如果我们可以将直方图，建模为两个正态分布（但可能重叠）的总和，那么可以使用一种称为“Optimal Thresholding、最佳阈值”的算法，该算法没有直观的解释其原理，但它不断的迭代，将产生最终结果。<br>算法如下：</p>
<ol>
<li>设置$t$为0，$T^t$=&lt;一些初始的阈值&gt;</li>
<li>根据当前阈值$T^t$，计算前景和背景的平均值<script type="math/tex; mode=display">
\begin{array}{ll}
w_{\mathrm{b}}\left(T^{t}\right)=\sum_{g=0}^{T^{\prime}-1} p(g) \quad \mu_{\mathrm{b}}\left(T^{\prime}\right)=\Sigma_{g=0}^{T^{\prime}-1} p(g) \cdot g / w_{\mathrm{b}}\left(T^{\prime}\right) \\
w_{\mathrm{f}}\left(T^{t}\right)=\sum_{g=T^{\prime}}^{255} p(g)=1-w_{\mathrm{b}}\left(T^{t}\right) \quad \mu_{\mathrm{f}}\left(T^{\prime}\right)=\sum_{g=T^{\prime}}^{255} p(g) \cdot g / w_{\mathrm{f}}\left(T^{\prime}\right)
\end{array}</script></li>
<li>设置$T^{t+1}=\left(\mu_{\mathrm{b}}\left(T^{t}\right)+\mu_{\mathrm{f}}\left(T^{t}\right)\right) / 2$以及将t增加1，为下一迭代更新阈值</li>
<li>回到第二步，直到$T^{t+1}=T^{t}$</li>
</ol>
<p>重要的是，设置的初始值必须能让某些对象和某些背景像素分离，否则算法将因除零错误而失败。另外，只有当直方图满足“两个正态分布的和的”假设时，该算法输出的结果才是最佳的选择。</p>
<h3 id="Otsu-Thresholding"><a href="#Otsu-Thresholding" class="headerlink" title="Otsu Thresholding"></a>Otsu Thresholding</h3><p>Optimal Thresholding 所假设的条件，通常不会成立，这时它的结果可能不可接受，所以Otsu定义了另一种方法，将阈值两边的像素值的分布最小化：  </p>
<p>考虑所有可能的阈值，并选择能使类方差$\sigma_{W}^{2}(T)$最小的阈值T：  </p>
<script type="math/tex; mode=display">
\sigma_{W}^{2}(T)=w_{\mathrm{f}}(T) \sigma_{f}^{2}(T)+w_{\mathrm{b}}(T) \sigma_{b}^{2}(T)</script><p>其中$w_{\mathrm{f}}(T)$和$w_{\mathrm{b}}(T)$分别是属于前景和背景部分的点，$\sigma_{f}^{2}(T)$和$\sigma_{b}^{2}(T)$分别是前景和背景灰度值的方差：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
w_{f}(T)=\sum_{g=T}^{255} p(g) & \sigma_{f}^{2}(T)=\sum_{g=T}^{255} p(g) \cdot\left(g-\mu_{f}(T)\right)^{2} / w_{\mathrm{f}}(T) \\
w_{\mathrm{b}}(T)=\sum_{g=0}^{T-1} p(g) & \sigma_{b}^{2}(T)=\sum_{g=0}^{T-1} p(g) \cdot\left(g-\mu_{b}(T)\right)^{2} / w_{\mathrm{b}}(T)
\end{array}</script><p>其中$\mu_{f}(T)$和$\mu_{b}(T)$分别是前景和背景的灰度值的均值。  </p>
<script type="math/tex; mode=display">
\mu_{f}(T)=\sum_{g=T}^{255} p(g) \cdot g / w_{\mathrm{f}}(T) \quad \mu_{b}(T)=\sum_{g=0}^{T-1} p(g) \cdot g / w_{\mathrm{b}}(T)</script><p>让类里方差最小的阈值也是能让类之间方差$\sigma_{B}^{2}(T)$最大的阈值，这是因为$\sigma_{B}^{2}(T)=\sigma^{2}-\sigma_{W}^{2}(T)$，其中$\mu$和$\sigma^{2}$是图像数据的均值和方差。<br>给两个类$f$和$b$，其类之间方差为：</p>
<script type="math/tex; mode=display">
\sigma_{B}^{2}(T)=w_{f}(T)\left(\mu_{f}(T)-\mu\right)^{2}+w_{b}(T)\left(\mu_{b}(T)-\mu\right)^{2}</script><p>进而简化为：</p>
<script type="math/tex; mode=display">
\sigma_{B}^{2}(T)=w_{f}(T) w_{b}(T)\left(\mu_{f}(T)-\mu_{b}(T)\right)^{2}</script><p>其中$\mu=w_{f}(T) \mu_{f}(T)+w_{b}(T) \mu_{b}(T)$<br>所以总的来说，就是遍历所有可能的阈值T，找到能使上式的类间方差最大的阈值，即为结果，可以看出我们只需计算前后部分的权重和均值，就能作出判断。</p>
<h2 id="Variations-on-Thresholding"><a href="#Variations-on-Thresholding" class="headerlink" title="Variations on Thresholding"></a>Variations on Thresholding</h2><h3 id="Adaptive-Thresholding"><a href="#Adaptive-Thresholding" class="headerlink" title="Adaptive Thresholding"></a>Adaptive Thresholding</h3><p>以上出现的技术中，都对全局进行阈值处理（即，将单个阈值应用于图像中的所有点）。但在某些情况下，也可以使用多个阈值来更好的改善阈值结果。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.7.png" alt="图4.7"></p>
<p>比如图4.7，其中若只用单个的全局最佳阈值，图中的大部分书面细节将消失。而使用自适应阈值处理（具有64个阈值/图像块），大多数细节都可以正确显示。其中，自适应阈值算法为：</p>
<ol>
<li>将图像划分为多个子图像（如在图4.7中，用8×8网格分割成64个子图像）。</li>
<li>对于每个子图像，分别计算阈值。</li>
<li>对于图像中的每个点，使用双线性插值从四个最近的阈值中插值一个阈值来确定该点的阈值。</li>
</ol>
<p>图4.7中可发现，该技术并非在所有地方都能正常工作，比如有两个黑色区域，对于这种情况，可以给全局的各个阈值添加限制来解决，以确保阈值在整个图像没有明显的变化。<br>重要的是，在OpenCV中，该技术并非本文介绍的那样，它计算的是当前像素，与以当前像素为中心的，<em>block_size</em>大小的像素块的局部平均值之间的差异，如果差异减去<em>offset</em>之后比0大，则设置输出值为255，反而设置为0，其中<em>block_size</em>对输出有很大影响，另外，也可以使用高斯加权平均值来代替局部平均值。实际上，基于局部区域的均值，相当于以另一种方式得到了当前像素的新阈值。</p>
<h3 id="Band-Thresholding"><a href="#Band-Thresholding" class="headerlink" title="Band Thresholding"></a>Band Thresholding</h3><p>Band Thresholding使用了两个阈值，一个在对象/物体的像素以下，另一个在对象/物体的像素以上：</p>
<script type="math/tex; mode=display">
\begin{array}{ralign}
\text{For all pixels } & (i, j) \\
f^{\prime}(i, j)&= 1 \text { for } f(i, j) \geq T_{1} \text { and } f(i, j) \leq T_{2}\\
&= 0 \text { otherwise}
\end{array}{}</script><p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.9.png" alt="图4.9"></p>
<p>如图4.9所示，该技术可以用于定位物体/对象的边界，虽然对于边界，边缘检测器会更可靠，更合适。</p>
<h3 id="Semi-Thresholding"><a href="#Semi-Thresholding" class="headerlink" title="Semi-Thresholding"></a>Semi-Thresholding</h3><p>半阈值化，对物体像素保留其原始灰度值，但将其背景像素设置为黑色。</p>
<script type="math/tex; mode=display">
\begin{array}{ralign}
\text{For all pixels } & (i, j) \\
f^{\prime}(i, j)&=f(i, j) \text { for } f(i, j) \geq T\\
&= 0 \text { otherwise}
\end{array}{}</script><p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.10.png" alt="图4.10"></p>
<p>结果图如图4.10所示。</p>
<h3 id="Multispectral-Thresholding"><a href="#Multispectral-Thresholding" class="headerlink" title="Multispectral Thresholding"></a>Multispectral Thresholding</h3><p>对于彩色图像，如果要应用阈值，最常见的做法是将图像转换为灰度，然后转换为阈值，不过也可以对每个通道独立应用阈值（如图4.11所示），甚至还可以在3D颜色空间内进行阈值设置（比如，如果一个像素的颜色，存在于3D色彩空间的特定子空间中，则将该像素定义为对象/物体像素）。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.11.png" alt="图4.11"></p>
<h2 id="Mathematical-Morphology"><a href="#Mathematical-Morphology" class="headerlink" title="Mathematical Morphology"></a>Mathematical Morphology</h2><p>数学形态学是一种，基于set operations、运算集的图像处理方法，这些运算集通常对物体的形状，进行非线性算子的代数运算。它提供了许多描述图像处理和分析操作的统一框架，并让一些很难描述的技术（以下内容）的开发成为可能。<br>其中，<strong>形态运算</strong>将structuring elements、结构元素有效地移动到图像中的每个可能的位置，并分别进行逻辑运算（以某种方式将结构元素与图像进行比较），并将运算结果存储在单独的输出图像中。  </p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.12.png" alt="图4.12"></p>
<p>操作过程中，将二值图像看作2D的网格，对象点就是网格中的点，且网格原点与原图的原点相同（如图4.12（a）所示）。而结构元素通常是围绕它们自己的原点（通常对称）定义的少量的对象点集。典型的结构元素是各向同性的（矩形中的所有点都属于结构元素），比如图4.12（b）和（c），但它不必是各向同性的，如图4.12（d）。</p>
<h3 id="Dilation"><a href="#Dilation" class="headerlink" title="Dilation"></a>Dilation</h3><p>膨胀是一种用于扩展物体/对象的像素数量的技术，如图4.13所示，它通常会同时在所有方向上扩展：</p>
<script type="math/tex; mode=display">
X \oplus B=\left\{p \in \varepsilon^{2} ; p=x+b, x \in X \text { and } b \in B\right\}</script><p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.13.png" alt="图4.13"></p>
<p>它将二值图像X中的每一个对象点x，转换为结构元素B中的每一个对象点b（相对于结构元素原点的对象点向量），所以图像X中的每一个对象点都能造成输出图像中出现一些对象点，但重复项不保留。<br>膨胀会增加物体的大小（即集合中的点数），从外观上来看，它会导致小孔被填充，并将较大的对象块之间的狭窄间隙填满。另外，一般用于图像中的扩散使用各向同性的结构元素。</p>
<h3 id="Erosion"><a href="#Erosion" class="headerlink" title="Erosion"></a>Erosion</h3><p>侵蚀是一种通过消除边界上的像素点，来缩小对象/物体形状的技术，如图4.15所示：</p>
<script type="math/tex; mode=display">
X \ominus B=\left\{p \in \varepsilon^{2} ; p+b \in X \text { for every } b \in B\right\}</script><p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.15.png" alt="图4.15"></p>
<p>由图可知，当且仅当为当前点转换时，结构元素所对应的所有点都是对象点，该点才是侵蚀输出集的元素，也可将其视为匹配问题，将结构元素与输入图像的每个可能位置进行匹配，只有完美匹配的点，才能被标记输出。<br>此操作会减少了对象的大小（即集合中的点数），即，消除任何小的噪声点，以及任何狭窄的特征。与膨胀类似，侵蚀一般也使用各向同性的结构元素。</p>
<h3 id="Opening-and-Closing"><a href="#Opening-and-Closing" class="headerlink" title="Opening and Closing"></a>Opening and Closing</h3><p>侵蚀可以看做是膨胀的镜像，反之亦然，一个扩大对象像素的数量，另一个缩小对象像素的数量，将这些操作结合在一起，就是开运算和闭运算。<br>开运算是先侵蚀再膨胀的操作，使用的结构元素相同：</p>
<script type="math/tex; mode=display">
X \mathrm{O} B=(X \ominus B) \oplus B</script><p>开运算可以消除噪点（消除比结构元素小的图像细节），以及较窄的特征（例如较大对象块之间的连接），并平滑对象边界。与侵蚀和膨胀不同，它能近似保持物体的大小。<br>而闭运算是先进行膨胀操作，再进行侵蚀操作，使用的结构元素相同：</p>
<script type="math/tex; mode=display">
X \cdot B=(X \oplus B) \ominus B</script><p>闭运算能连接互相接近的对象，并填充对象内的孔。它倾向于使对象的形状有些变形，但也能近似保持物体的大小。<br>在许多应用中，通常会先进行一个闭运算然后进行一个开运算，来搭理二值图像，如图4.17和图4.18。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.17.png" alt="图4.17"></p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.18.png" alt="图4.18"></p>
<h3 id="Grey-Scale-and-Colour-Morphology"><a href="#Grey-Scale-and-Colour-Morphology" class="headerlink" title="Grey-Scale and Colour Morphology"></a>Grey-Scale and Colour Morphology</h3><p>除了二值图像，形态学运算也可以应用于灰度和彩色图像。在这些情况下，各个通道上的每个不同的灰度层级（level）都被单独视为一个集合（即，所有大于或等于<strong>特定灰度级别</strong>的点），如图4.19所示。图4.20和图4.21，分别是对灰度图像以及颜色图像进行开运算和闭运算的示例。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.19.png" alt="图4.19"></p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.20.png" alt="图4.20"></p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.21.png" alt="图4.21"></p>
<p>具体来说，可以理解为，对给定像素进行结构像素的匹配，找到对应区域的最小值或最大值，膨胀的公式如下：</p>
<script type="math/tex; mode=display">
\delta_{B}(f)_{x}=(f \oplus B)_{x}=\max _{\beta \in B} f(x+\beta)</script><p>侵蚀的公式如下：</p>
<script type="math/tex; mode=display">
\varepsilon_{B}(f)_{x}=(f \ominus B)_{x}=\min _{\beta \in B} f(x+\beta)</script><p>开运算和闭运算不再赘述。</p>
<h2 id="Connectivity"><a href="#Connectivity" class="headerlink" title="Connectivity"></a>Connectivity</h2><p>在进行阈值处理以及噪声清理后，就需要在场景中定位对象了，而定位则需要确定哪些像素实际连在一起，如图4.22所示。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.22.png" alt="图4.22"></p>
<h3 id="Connectedness-Paradoxes-and-Solutions"><a href="#Connectedness-Paradoxes-and-Solutions" class="headerlink" title="Connectedness: Paradoxes and Solutions"></a>Connectedness: Paradoxes and Solutions</h3><p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.23.png" alt="图4.23"></p>
<p>见上图左边，可以发现，两条线虽然相交，表现为连续的，但是并不属于同一部分，而右边可以发现，两个似乎连续的两个圆，在同样似乎连续的背景上。这两个图展示了可能会遇到的一些问题，虽然在二值图中，右边的图才更有意义。<br>在确定哪些像素相邻时，首先要选择两种方案：4邻接，仅将东、南、西、北的像素视为相邻；以及8邻接，将所有直接围绕的像素视为相邻，见图4.24所示。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.24.png" alt="图4.24"></p>
<p>从理论上讲，我们希望使用像素的相邻性，来构建连续的整块区域，既区域中的任意两个点都可以用属于该区域的点连接起来。此类区域，相对于背景而言也就是对象/物体（有可能含有孔）。但是对于图4.23中的圆来说，无论是4邻接还是8邻接都无法得到预期的结果，如图4.25所示。  </p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.25.png" alt="图4.25"></p>
<p>解决此问题的一种思路是，同时使用4邻接和8邻接：</p>
<ul>
<li>对于外部背景使用4邻接原则。 </li>
<li>对于外部物体/对象使用8邻接原则。</li>
<li>对于孔使用4邻接原则。</li>
<li>对于孔中的物体使用8邻接原则。</li>
</ul>
<p>效果如图4.26所示。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.26.png" alt="图4.26"></p>
<h3 id="Connected-Components-Analysis"><a href="#Connected-Components-Analysis" class="headerlink" title="Connected Components Analysis"></a>Connected Components Analysis</h3><p>在解决了连通性悖论后，需要一种实用的算法来给每个像素贴标签，这里的像素仅指二值图像中的对象像素，所以不用担心连接性问题，故可以仅使用8邻接和4邻接的其中一个来为像素贴标签（因为基于先前的相邻像素），见图4.27。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.27.png" alt="图4.27"></p>
<p>算法如下：</p>
<ol>
<li>在图像中逐行搜索，并在每行里逐列搜索：<br> 对于每个非零的像素：<pre><code> 如果所有先前的相邻像素，都是背景像素：
     给当前像素赋予新的标签
 否则：
     从先前的相邻像素的标签中,任选一个作为当前像素的标签
     如果任何两个先前的相邻像素之间有不同的标签：
         将这些标签记下为等效的
</code></pre></li>
<li>遍历整个图像，将等效的标签都设置为相同的标签值。</li>
</ol>
<p>算法说明见图4.28，效果见4.29。</p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.28.png" alt="图4.28"></p>
<p><img src="/2020/08/06/读书笔记-计算机视觉入门介绍/4.29.png" alt="图4.29"></p>
<p>总的来说，我们用阈值来处理图像时，能将之分成不同的两个区域，再使用CCA（连接成分分析），能让我们走的更远，并能标记连接起来的二元区域，而分出来的区域会更加多且细。<br>另外，通常情况是会同时标记物体的点和背景的点，所以应该对物体使用8邻原则，对背景/孔使用4邻原则。</p>
<h1 id="Geometric-Transformations"><a href="#Geometric-Transformations" class="headerlink" title="Geometric Transformations"></a>Geometric Transformations</h1></0></\text></\text></0.5>
      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/计算机视觉/" rel="tag"># 计算机视觉</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/28/Dynamic-Programming/" rel="next" title="Dynamic Programming">
                <i class="fa fa-chevron-left"></i> Dynamic Programming
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">29</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">21</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Histogram-Image-Equalisation"><span class="nav-number">1.</span> <span class="nav-text">Histogram/Image Equalisation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Histogram-Comparison"><span class="nav-number">2.</span> <span class="nav-text">Histogram Comparison</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Back-projection"><span class="nav-number">3.</span> <span class="nav-text">Back-projection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k-means-Clustering"><span class="nav-number">4.</span> <span class="nav-text">k-means Clustering</span></a></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#Binary-Vision"><span class="nav-number"></span> <span class="nav-text">Binary Vision</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Thresholding"><span class="nav-number">1.</span> <span class="nav-text">Thresholding</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Thresholding-Problems"><span class="nav-number">1.1.</span> <span class="nav-text">Thresholding Problems</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Threshold-Detection-Methods"><span class="nav-number">2.</span> <span class="nav-text">Threshold Detection Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Bimodal-Histogram-Analysis"><span class="nav-number">2.1.</span> <span class="nav-text">Bimodal Histogram Analysis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimal-Thresholding"><span class="nav-number">2.2.</span> <span class="nav-text">Optimal Thresholding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Otsu-Thresholding"><span class="nav-number">2.3.</span> <span class="nav-text">Otsu Thresholding</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Variations-on-Thresholding"><span class="nav-number">3.</span> <span class="nav-text">Variations on Thresholding</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Adaptive-Thresholding"><span class="nav-number">3.1.</span> <span class="nav-text">Adaptive Thresholding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Band-Thresholding"><span class="nav-number">3.2.</span> <span class="nav-text">Band Thresholding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Semi-Thresholding"><span class="nav-number">3.3.</span> <span class="nav-text">Semi-Thresholding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multispectral-Thresholding"><span class="nav-number">3.4.</span> <span class="nav-text">Multispectral Thresholding</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mathematical-Morphology"><span class="nav-number">4.</span> <span class="nav-text">Mathematical Morphology</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dilation"><span class="nav-number">4.1.</span> <span class="nav-text">Dilation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Erosion"><span class="nav-number">4.2.</span> <span class="nav-text">Erosion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Opening-and-Closing"><span class="nav-number">4.3.</span> <span class="nav-text">Opening and Closing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Grey-Scale-and-Colour-Morphology"><span class="nav-number">4.4.</span> <span class="nav-text">Grey-Scale and Colour Morphology</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Connectivity"><span class="nav-number">5.</span> <span class="nav-text">Connectivity</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Connectedness-Paradoxes-and-Solutions"><span class="nav-number">5.1.</span> <span class="nav-text">Connectedness: Paradoxes and Solutions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Connected-Components-Analysis"><span class="nav-number">5.2.</span> <span class="nav-text">Connected Components Analysis</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Geometric-Transformations"><span class="nav-number"></span> <span class="nav-text">Geometric Transformations</span></a></li></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  













  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  

  


  


  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  


  

</body>
</html>
