<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>



  <meta name="description" content="上一本书的笔记做完之后，想了很多，笔记的作用一是记下自己的理解，方便日后观看，二是能防止自己走神，但是感觉之前做笔记的过程有些变味了，完全变成照抄，完全没有思考，所以这本书的笔记，会精简一些，但是也会尽量表达自己的想法，必要的地方做些摘抄，不过这本书是英文的，想写成中文笔记，本身也需要花费些精神呢。   这本书叫《Deep Learning-Bengio》，以下是笔记部分。">
<meta name="keywords" content="深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="读书笔记 - Deep Learning-Bengio">
<meta property="og:url" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="上一本书的笔记做完之后，想了很多，笔记的作用一是记下自己的理解，方便日后观看，二是能防止自己走神，但是感觉之前做笔记的过程有些变味了，完全变成照抄，完全没有思考，所以这本书的笔记，会精简一些，但是也会尽量表达自己的想法，必要的地方做些摘抄，不过这本书是英文的，想写成中文笔记，本身也需要花费些精神呢。   这本书叫《Deep Learning-Bengio》，以下是笔记部分。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/1.1.png">
<meta property="og:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/1.2.png">
<meta property="og:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/1.3.png">
<meta property="og:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/4.3.png">
<meta property="og:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/10.3.png">
<meta property="og:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/10.4.png">
<meta property="og:updated_time" content="2020-03-16T15:08:24.234Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="读书笔记 - Deep Learning-Bengio">
<meta name="twitter:description" content="上一本书的笔记做完之后，想了很多，笔记的作用一是记下自己的理解，方便日后观看，二是能防止自己走神，但是感觉之前做笔记的过程有些变味了，完全变成照抄，完全没有思考，所以这本书的笔记，会精简一些，但是也会尽量表达自己的想法，必要的地方做些摘抄，不过这本书是英文的，想写成中文笔记，本身也需要花费些精神呢。   这本书叫《Deep Learning-Bengio》，以下是笔记部分。">
<meta name="twitter:image" content="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/1.1.png">





  
  
  <link rel="canonical" href="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>读书笔记 - Deep Learning-Bengio | Hexo</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/24/读书笔记-Deep-Learning-Bengio/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">读书笔记 - Deep Learning-Bengio

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-09-24 17:53:20" itemprop="dateCreated datePublished" datetime="2019-09-24T17:53:20+08:00">2019-09-24</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-03-16 23:08:24" itemprop="dateModified" datetime="2020-03-16T23:08:24+08:00">2020-03-16</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/读书笔记/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>上一本书的笔记做完之后，想了很多，笔记的作用一是记下自己的理解，方便日后观看，二是能防止自己走神，但是感觉之前做笔记的过程有些变味了，完全变成照抄，完全没有思考，所以这本书的笔记，会精简一些，但是也会尽量表达自己的想法，必要的地方做些摘抄，不过这本书是英文的，想写成中文笔记，本身也需要花费些精神呢。  </p>
<p>这本书叫《Deep Learning-Bengio》，以下是笔记部分。</p>
<p><a id="more"></a>\</p>
<h1 id="Deep-Learning-for-AI"><a href="#Deep-Learning-for-AI" class="headerlink" title="Deep Learning for AI"></a>Deep Learning for AI</h1><p>最开始AI是在一种纯粹的环境下诞生的，比如下棋，就是在一个规则固定且相对简单的环境中寻找制胜策略，这对于计算机来说自然是简单的，也不需要学习，但是这对于人类来说，却是相当抽象且困难。相反，人类日常的简单生活却是需要相当多的主观和直觉信息，这不是简单的几项规则能够概括的，那计算机又要怎样才能做到呢？<br>依赖硬编码知识的AI系统的瓶颈体现在系统需要能从原始数据中提取一定的模式，以获得自己的知识。这也就是机器学习。而机器学习的引进让机器能处理需要真实世界信息的问题，并做出近似主观的判断，出现了像逻辑回归(<em>logistic regression</em>)和朴素贝叶斯(<em>naive Bayes</em>)的方法。<br>但是这些算法不能知道那些特征是有用的，也不能注意到特征本身，如果给的不是一个格式化的报告，而是简单的原数据，算法也不能做出有用的判断。也很正常，数据的展示与结构本身就能对机器学习的效果有巨大的影响，如果特征提取设计的好，效果能大大提升，但是事实上，对于大部分的任务，人们都很难提取出正确的特征，不论是物体识别还是什么任务，人们都很难设计出怎样的像素才是对应的物体，更不用说各种各样的环境对物体表面的影响了。<br>其中一种处理办法就是使用机器学习去不仅仅学习数据表达与输出的对应，还要学习表达本身，这可以理解为表达学习(<em>representation learning</em>)，这就取代了模式特征的设计阶段，且有时能比人类设计的特征更好，并增加了AI系统自主快速适应新任务的能力，大大减少了人们进行特征设计及研究的时间。<br>当人们设计特征的时候，人们往往倾向于寻找因素(<strong>Factors</strong>)，即影响最终结果的因素，因素之间往往不是通过“乘”来实现的，而这些因素大多数不是直接观察到的，而是人们主观想到的，为多种多样的结果解释，比如演讲里面的演讲者的口音、年龄及性别等等。<br>但是有时因素太多，有时特征又太复杂，太抽象，就算是人也设计不出结构化的表达。<br>而深度学习，引入了表达学习，将表达以一种其他地，更简单的方式展示。比如下图：<br><img src="/2019/09/24/读书笔记-Deep-Learning-Bengio/1.1.png" alt=""><br>深度学习让计算机去学习一个多步(multi-step)的计算机程序，每层都能看成是计算机内存的一个状态。<br>总的来说，深度学习就是AI的一种，也是机器学习的一种，让计算机系统从经验和数据中提升，<br><img src="/2019/09/24/读书笔记-Deep-Learning-Bengio/1.2.png" alt=""><br>关系就像上面所形容的那样。<br>而数据的流动过程如下：<br><img src="/2019/09/24/读书笔记-Deep-Learning-Bengio/1.3.png" alt=""></p>
<h3 id="1-3-Historical-Perspective-and-Neural-Networks"><a href="#1-3-Historical-Perspective-and-Neural-Networks" class="headerlink" title="1.3 Historical Perspective and Neural Networks"></a>1.3 Historical Perspective and Neural Networks</h3><p>现代的深度学习研究从先前的神经网络的研究获得了很多启示，其它的深度学习里面的研究还有概率建模和图形模型还有其它多种多样的学习工作。</p>
<h3 id="1-5-Challenges-for-Future-Research"><a href="#1-5-Challenges-for-Future-Research" class="headerlink" title="1.5 Challenges for Future Research"></a>1.5 Challenges for Future Research</h3><p>虽然深度学习已经有这样的成功，但是现有科技仍然与当前的动物的信息处理能力和感知能力有巨大的差距，要了解到这些架构之后的规则就还需要更多基础科学的研究。<br>深度学习是很重要的工具，但它却不是AI的唯一解答。<br>而今后的深度学习的重要的突破口在于：</p>
<blockquote>
<ol>
<li>在无监督学习之后怎么应对基础的问题，比如说困难的推理和采样。</li>
<li>怎么构建并训练出更大，更具有适应性且可重构的复杂结构，以最大化在更大的数据集上训练的优点。</li>
<li>怎么提高深度学习算法的能力来弄清变化的潜在因素，或者搞清楚我们周围的这个世界。</li>
</ol>
</blockquote>
<h1 id="Linear-algebra"><a href="#Linear-algebra" class="headerlink" title="Linear algebra"></a>Linear algebra</h1><p>线性代数是数学的一个分支，线性代数的掌握对于理解深度学习即其算法很必要。  </p>
<p>细节略</p>
<h1 id="Probalility-and-Information-Theory"><a href="#Probalility-and-Information-Theory" class="headerlink" title="Probalility and Information Theory"></a>Probalility and Information Theory</h1><p>概率论是用来描述不确定性规则的数学工具，它提供了量化不确定性的方法，以及推导新概率的公式。且概率论是许多科学和工程学科的基础工具。</p>
<p>细节略</p>
<h1 id="Numerical-Computation"><a href="#Numerical-Computation" class="headerlink" title="Numerical Computation"></a>Numerical Computation</h1><p>机器学习算法通常需要大量的数值运算，这些算法并不是通过公式解析求得正确结果而是通过迭代更新解的估计值。包括线性方程组和最大最小值时的参数值。  </p>
<h3 id="4-1-Overflow-and-underflow"><a href="#4-1-Overflow-and-underflow" class="headerlink" title="4.1 Overflow and underflow"></a>4.1 Overflow and underflow</h3><p>Underflow是指在计算机中接近0的数因为计算机架构的原因被取整到0，如果该数字之后被用于分母，那么就会出错，而Overflow则是大尺度的数字被估计为∞或-∞，在该数字上无法再进行有效的计算。<br>举个例子，以softmax函数为例：</p>
<script type="math/tex; mode=display">
\operatorname{softmax}(\boldsymbol{x})_{i}=\frac{\exp \left(x_{i}\right)}{\sum_{j}^{n} \exp \left(x_{j}\right)}</script><p>如果c是一个很小的负数，那么exp(c)将会underflow，分母将为0，结果将出错，而若c是很大的正数，exp(c)将会overflow，这都将导致错误，当然可以用$\operatorname{softmax}(\boldsymbol{z}) \text { where } \boldsymbol{z}=\boldsymbol{x}-\max _{i} \boldsymbol{x}_{i}$来解决这个问题，</p>
<h3 id="4-2-Poor-conditioning"><a href="#4-2-Poor-conditioning" class="headerlink" title="4.2 Poor conditioning"></a>4.2 Poor conditioning</h3><p>条件(conditioning)指的是一个方程在输入值轻微变化的时候，做出迅速的改变。这在进行科学运算的时候就会引出一些问题，因为四舍五入的误差会引起输出值的巨大的不同。<br>比如有一个方程为$f(\boldsymbol{x})=\boldsymbol{A}^{-1} \boldsymbol{x}$，当A为一个一个特征值分解，那么它的条件数(最大和最小特征值的大小之比)就是：</p>
<script type="math/tex; mode=display">
\max _{i, j}\left|\frac{\lambda_{i}}{\lambda_{j}}\right|</script><p>当这个数大的时候，矩阵的逆就对输入的偏差特别敏感。而且这个是矩阵本身的特性，当我们与真矩阵值相乘时，就会放大这个预先存在的错误。</p>
<h3 id="4-3-Gradient-Based-Optimization"><a href="#4-3-Gradient-Based-Optimization" class="headerlink" title="4.3 Gradient-Based Optimization"></a>4.3 Gradient-Based Optimization</h3><p>大多数的学习算法都会涉及某种优化，而优化则是通过改变x，来最大化或最小化函数值。这个函数值就是目标函数(<strong>objective function</strong>)，若是最小化，也可以叫它损失函数(<strong>cost/loss/error function</strong>)，通过在使得函数值最大或最小的x值旁边加上<em>，即$x^{</em>}=\arg \min f(\boldsymbol{x})$。<br>通过求导数，可以知道函数在一个点的倾斜度，它表示了y会对于x的小变化做出多少倍的反应，所以导数能够被用来最小化一个函数，因为它告诉了应该怎么改变x值，才能得到更优化的y值。但是当函数值比周围点的函数值都小时，就到达了局部最大(小)值，就很难通过缓慢移动来提升函数值了。<br>除此之外，深度学习也很容易走到局部最小值而非全局最优值，在非常平的地方也会出现问题，或者在很平的地方周围出现很多鞍点，特别是当输入是多维的时候。所以如下图：<br><img src="/2019/09/24/读书笔记-Deep-Learning-Bengio/4.3.png" alt=""><br>当局部极值过多，对于深度学习，有时候也只能接受，只要它和最值接近。  </p>
<p>当优化方程有众多输入：$f : \mathbb{R}^{n} \rightarrow \mathbb{R}$，那就必须要用到偏导数了，它显示了单个变量在某点对函数值的影响，而一个函数f的梯度则是包含了函数所有偏导数的矩阵，表示为$\nabla_{\boldsymbol{x}} f(\boldsymbol{x})$，其中关键点就是梯度里面的每个元素值都是0。<br>在方向u(单位向量)上的方向导数，是函数f在方向u上的倾斜度。也就是说函数$f(\boldsymbol{x}+\alpha \boldsymbol{u})$关于α的导数，在α为0时，使用链式法则，可以得到$\boldsymbol{u}^{\top} \nabla_{\boldsymbol{x}} f(\boldsymbol{x})$。<br>为了最小化f，就是要找到f下降最快的方向：</p>
<script type="math/tex; mode=display">
\begin{aligned} \min _{\boldsymbol{u}, \boldsymbol{u}^{\top} \boldsymbol{u}=1} \boldsymbol{u}^{\top} \nabla_{\boldsymbol{x}} f(\boldsymbol{x}) \\=\min _{\boldsymbol{u}, \boldsymbol{u}^{\top} \boldsymbol{u}=1}\|\boldsymbol{u}\|_{2}\left\|\nabla_{\boldsymbol{x}} f(\boldsymbol{x})\right\|_{2} \cos \theta \end{aligned}</script><p>其中$\theta$是u和梯度的夹角，代替$|\boldsymbol{u}|_{2}=1$，忽视不依赖于u的元素，方程就简化到了$\min _{u} \cos \theta$，当u与梯度相反时，达到最小值，也就是说，梯度直接指向上坡，而负梯度直接指向下坡，沿着负梯度方向移动f就能减少f值，这就是最速下降法或者说梯度下降法(steepest descent or gradient descent)，最陡的下降就到了新的点：</p>
<script type="math/tex; mode=display">
\boldsymbol{x}^{\prime}=\boldsymbol{x}-\epsilon \nabla_{\boldsymbol{x}} f(\boldsymbol{x})</script><p>其中$\epsilon$就是步长大小，有很多方法可以设置，比如将之设置为小的常量，有时也可以解决由于步长设置而引起的梯度消失问题，或者根据$f\left(\boldsymbol{x}-\epsilon \nabla_{\boldsymbol{x}} f(\boldsymbol{x})\right)$选择一系列的$\epsilon$，并选择最小函数值的结果，这一策略叫作线搜索。<br>当梯度的每一个元素都变为0，或者趋于0时，下降就收敛了，在某些例子中，可以直接求解方程$\nabla_{\boldsymbol{x}} f(\boldsymbol{x})=0$，直接就跳到关键点，以避免不停的迭代。<br>求得导数的导数有时候也会有所用处，也就是二阶导数，比如$\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} f$就是对于，f在$x_{j}$上的导数在$x_{i}$上的导数，导数的顺序可以交换，即$\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} f=\frac{\partial^{2}}{\partial x_{j} \partial x_{i}} f$。<br>二阶导数能告诉我们，当改变输入时，一阶导数是怎么改变的，也就能用来判断一个关键点是一个局部极大值，局部最小值还是一个鞍点。因为这些点都$f^{\prime}(x)=0$，但是若$f^{\prime \prime}(x)&gt;0$，则是局部最小值，若$f^{\prime \prime}(x)&lt;0$，则为局部最大值，但是若$f^{\prime \prime}(x)=0$，结果有可能是鞍点也有可能是一片平的区域。<br>记录二阶导数的矩阵是黑塞矩阵(<strong>Hessian matrix</strong>，又译作海森矩阵、海塞矩阵或海瑟矩阵等)，可以记录为：$$<br>\boldsymbol{H}(f)(\boldsymbol{x})_{i, j}=\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} f(\boldsymbol{x})</p>
<script type="math/tex; mode=display">
事实上黑塞矩阵就是雅克布矩阵(**Jacobian matrix**)的梯度。  
但是如下图所示：
![](./读书笔记-Deep-Learning-Bengio/4.4.png)
对于多维度的点来说，有可能在某一维度上是局部最大值，而在另一维度上是局部最小值，所以从多维度的二阶导数就难以得出结论了。  
同样，从黑塞的条件数不是很好时，梯度下降就表现的不是很好了，比如在一个方向上，导数快速增加，而在另一个方向，导数缓慢增加。梯度下降并没有意识到导数的这种变化，因此它不知道要优先在导数保持负数的方向上探索。比如下图中所示：
![](./读书笔记-Deep-Learning-Bengio/4.5.png)
对Hessian矩阵的条件数为5的二次函数使用梯度下降（曲率在一个方向上比在其他方向上大5倍），其中红线为梯度下降的曲线，这种非常细长的二次函数类似于长长的峡谷，因为太过于陡峭，而不断浪费时间重复地在峡谷壁上下降。因为步长过大，而可能越过谷底，所以黑塞矩阵的最大特征值指向的方向就是下降最快的地方，所以可以得出，沿着最陡的方向在这种情况下反而不是最理想的。  
从黑塞矩阵得出的信息同样可以用来解决这个问题，比如牛顿法(**Newton’s method**)，它通过一个二阶泰勒级数展开式来近似的估计f(x)在接近点$x_{0}$的值：</script><p>f(\boldsymbol{x})=f\left(\boldsymbol{x}_{0}\right)+\left(\boldsymbol{x}-\boldsymbol{x}_{0}\right)^{\top} \nabla_{\boldsymbol{x}} f\left(\boldsymbol{x}_{0}\right)+\frac{1}{2}\left(\boldsymbol{x}-\boldsymbol{x}_{0}\right)^{\top} H(f)\left(\boldsymbol{x}_{0}\right)\left(\boldsymbol{x}-\boldsymbol{x}_{0}\right)</p>
<script type="math/tex; mode=display">
解出来有：</script><p>\boldsymbol{x}^{*}=\boldsymbol{x}_{0}-H(f)\left(\boldsymbol{x}_{0}\right)^{-1} \nabla_{\boldsymbol{x}} f\left(\boldsymbol{x}_{0}\right)</p>
<script type="math/tex; mode=display">
所以当函数可以局部近似为二次函数时，迭代更新近似值并跳转到近似值的最小值可以比梯度下降更快地到达临界点了。

### 4.4 Constrained optimization

有时，并不想最大化或最小化一个函数，而是找到函数在S集上的极值，也就是约束优化，一种简单的解决办法是直接修改，让梯度下降注意到限制：如果用定值步长，则做梯度下降后，将结果与S比对，如果用线搜索，则我们只能搜索能产生可行点的步长，也可以将线上的每个点投影回约束区域。  
更复杂的，可以设计一个不同的不受限制的优化算法，而其结果可以被转换到原始的受限制的问题中，比如极坐标转换等等。  
拉格朗日乘子法(**Lagrange multipliers**)则设计了一个拉格朗日方程，引入了新的额外的变量，叫拉格朗日乘子。这里有一篇拓展[深入理解拉格朗日乘子法](https://www.cnblogs.com/mo-wang/p/4775548.html)

### 4.5 例子：线性最小二乘法

# Machine Learning Basics

深度学习是机器学习的特殊的一种，机器学习是深度学习的基础。

### 5.1 Learning algorithms

对于学习来说有一个定义，"如果说计算机程序可以从有关某类任务T和效果指标P的信息中学习经验E，则计算机程序在任务T中，由标准P衡量，会随着经验而提高"。

#### 5.1.1 The task, T

从工程的角度来想，机器学习使我们能够解决，人类编写和设计的固定程序难以解决的任务。而从科学和哲学的角度来看，机器学习很有趣，因为对理解它能使我们能够理解智能行为背后的原则。进而能够被设计着去完成一定任务：
> Classification(分类)：这个算法目的是输出一个函数$f: \mathbb{R}^{n} \rightarrow\{1, \ldots, k\}$，用来预测x所属的种类，或者输出x属于各个种类的概率值，使用场景比如物体识别等。  
> Classification with missing inputs(输入缺失的分类)：似于分类，但是它不提供单个分类功能外。对于x类的分类，每个函数的输入都缺少了部分子集。这种情况在医学诊断中经常出现，因为许多医学测试价格昂贵等原因。  
> Regression(回归)：函数要输出$f: \mathbb{R}^{n} \rightarrow \mathbb{R}$，与分类类似，但是系统会输出实值而不是类别。  
> Transcription(转录)：这与分类类似，但是输出是一系列的符号，而不是一个分类号码(单个符号)，比如在语音识别或者机器翻译时，就要输出一串字，这样的任务属于结构化输出任务，目标是输出一个复杂的组合对象，其中包含许多随机变量(例如翻译后句子中的单个单词)，这些变量具有非平凡的联合分布。  
> Density estimation(密度计算)：机器学习算法要学习一个函数$p_{model}: \mathbb{R}^{n} \rightarrow \mathbb{R}$，其中$p_{model}$可以理解为从示例中提取出的空间上的概率密度函数，要做的效果好，算法需要学习已有的数据的结构，它必须知道给出的示例在哪里聚集紧密以及不太可能发生在哪里。这可以用于异常检测，但原则上也可以（以某种计算为代价）用于回答以下形式的所有问题：给定x的变量的一部分子集，那x中的变量的其他子集可能的值是多少(或期望值是什么或其他此类统计量)。它类似于一种无监督学习。  
> Anomaly detection(异常检测)：算法在这里用来检测哪些事件是正常的，哪些事件不太正常，比如通过对你的购买习惯进行建模，信用卡公司就可以检测到你的信用卡的一些异常行为，比如有人盗刷，大概率与你的购物习惯不太相同，就能有效避免诈骗。  
> Synthesis and sampling(合成和采样)：在某些任务中，机器学习算法要生成一些与训练数据类似的新案例，这对于媒体应用程序很有用，因为对于媒体应用程序而言，让艺术家手工制作大量内容可能既昂贵又无聊(比如淘宝首页配图或者电子游戏可以自动为大型物体或风景生成纹理，而不需要艺术家手动标记每个像素)。  
> Imputation of missing values(估算缺失值)：机器学习算法被给予一个值$\mathbf{x} \in \mathbb{R}^{n}$，但是x中的部分条目值$x_{i}$缺失了，那么该算法必须提供丢失条目值的预测，这与密度计算有些类似。

#### 5.1.2 The performance measure, P

为了衡量机器学习算法的性能，必须就要设计一个性能的量化机制，通常来说，机制P是专门为了系统所需任务T而设计的。  
对于Classification、Classification with missing inputs和transcription这种任务来说，通常测量模型的**准确率**(**accuracy**)，这是模型产生正确输出占全部输出的比例，而对于密度估计之类的任务，可以测量模型分配给某些示例的概率。  
通常，我们比较关心算法在它从来没有见过的数据上能表现的多好，因为这展示了将算法用于真实世界时，能有怎样的表现，所以需要用测试数据。  
性能测量有时候叫*loss*，展示了某一特定事件的损失，而目标就是最小化loss。  
对于测量标准的选择似乎是简单而客观的，但是通常很难选择与系统需求完全吻合的性能指标。首先是不知道选择哪个来测量，再者，我们知道理想情况下要测量多少个，但是实际上测量却是不切实际的。最后，在机器学习中，目标是调整模型的参数以优化其性能，然而在许多情况下，相关的性能指标不适合直接应用于优化过程，为了直接优化性能指标，我们就需要一个平滑的信号（例如梯度），以便让我们知道如何移动模型参数以改善性能指标。比如对于分类任务来说，参数的微小变化对于输出并不会有什么影响，所以就不会有局部信号来告诉网络应该怎么更新模型参数来更新模型性能。  

#### 5.1.3 The experience, E

通常，经验是让算法去观察一个包含一些例子的数据集，这相对来说比较简单，其他方法要提供更加丰富和相互作用的经验。  
一个数据集是一个样本的集合，每个样本都是观察到的信息的集合，叫作特征。通常用矩阵表示。

### 5.2 Example: Linear regression

模型函数里面的权值决定了各个特征最后结果的影响。
${MSE}_{test}$表示了在测试集上的误差，而为了改善权值，就要最小化在训练集上的误差(动机见5.6)，而为了最小化${MSE}_{train}$，可以去寻找梯度为0的地方：</script><p>\begin{array}{c}{\nabla_{\mathbf{w}} \operatorname{MSE}_{\text {train }}=0} \\ {\Rightarrow \nabla_{\mathbf{w}} \frac{1}{m}\left|\hat{\mathbf{y}}^{(\text {train })}-\mathbf{y}^{(\text {train })}\right|_{2}^{2}=0} \\ {\Rightarrow \frac{1}{m} \nabla_{\mathbf{w}}\left|\mathbf{X}^{(\text {train })} \mathbf{w}-\mathbf{y}^{(\text {train })}\right|_{2}^{2}=0}\end{array}</p>
<script type="math/tex; mode=display">
</script><p>\begin{array}{c}{\Rightarrow \nabla_{\mathbf{w}}\left(\mathbf{X}^{(\text {train })} \mathbf{w}-\mathbf{y}^{(\text {train })}\right)^{\top}\left(\mathbf{X}^{(\text {train })} \mathbf{w}-\mathbf{y}^{(\text {train })}\right)=0} \\ {\Rightarrow \nabla_{\mathbf{w}}\left(\mathbf{w}^{\top} \mathbf{X}^{\text {(train) }} \mathbf{X}^{(\text {train })} \mathbf{w}-2 \mathbf{w}^{\top} \mathbf{X}^{(\text {train }) \top} \mathbf{y}^{(\text {train })}+\mathbf{y}^{(\text {train }) \top} \mathbf{y}^{(\text {train })}\right)=0} \\ {\Rightarrow 2 \mathbf{X}^{(\text {train }) \top} \mathbf{X}^{(\text {train })} \mathbf{w}-2 \mathbf{X}^{(\text {train }) \top} \mathbf{y}^{(\text {train })}=0} \\ {\Rightarrow \mathbf{w}=\left(\mathbf{X}^{(\text {train }) \top} \mathbf{X}^{(\text {train })}\right)^{-1} \mathbf{X}^{(\text {train })} \mathbf{y}^{(\text {train })}}\end{array}</p>
<script type="math/tex; mode=display">
以上的推导过程就是正规方程。权值的影响如下：
![](./读书笔记-Deep-Learning-Bengio/5.1.png)

### 5.3 Generalization, Capacity, Overfitting and Underfitting

#### 5.3.1 Generalization

泛化性几乎是机器学习都想要优化的目标，是最感兴趣的问题，输入千千万，训练器难以保证能从训练集中泛化到新的类别中。

#### 5.3.2 Capacity 

**Capacity**展示了一个学习器在或多或少的函数中，发现所需要的函数的能力。比如一个学习器能永远fit的样本数目的多少。  
比如有时候二元函数会欠拟合，而多元函数会过拟合。在深度学习中体现为神经元的深浅多少

#### 5.3.3 Occam's Razor, Underfitting and Overfitting

机器学习的一个很重要的需要权衡(trade-off)的东西就是capacity和generalization，它源自一个更古老的想法 - Occam's Razor。需要能解释观察到的数据的函数，就需要简单一点的函数。但是这在遇到复杂模型就会欠拟合，但是过于复杂一点的模型又会难以训练。或者说模型本身就难以训练，卡在了局部最小值也是有可能的。或者尽管模型具有足够的任务处理能力，但优化过程无法找到能很好地逼近目标函数的解决方案。尽管在实践中通常很难将这两种效应分离开，但这种不拟合的原因在深度学习方法中相当普遍。这就是为什么如此强调促进更有效的优化的模型和方法的原因之一。  
而过拟合就是拟合的太过，反而失去了泛化的特性。  
有时为了确定capacity是否选用恰当，可以使用验证集来监视泛化的能力，当数据集小的时候，甚至可以使用交叉验证来辅助
![](./读书笔记-Deep-Learning-Bengio/5.3.png)
上图展示了capacity的特性。

### 5.5 Estimators, Bias, and Variance

使用样本均值与已知真实均值讨论样本方差和协方差，以上的概念都是从数值分析里面引用过来的。

#### 5.5.1 Point Estimation

点估计是去尝试，在一组兴趣点里面找到单一“最佳”预测，其中兴趣点里面包括一些参数模型里面的单一参数或者参数向量。  
如果用$x_{1},...,x_{n}$表示n个独立的相同分布的数据点，那么点估计就是要找到</script><p>\hat{\theta}_{n}=g\left(x_{1}, \ldots, x_{n}\right)</p>
<script type="math/tex; mode=display">
的函数，点估计就可以引申理解为对输入和目标变量之间关系的预测，这种点估计也可以叫作函数估计(**Function Estimation**)。  

#### 5.5.2 Bias
偏差可以理解为：</script><p>\operatorname{bias}\left(\hat{\theta}_{n}\right)=\mathbb{E}\left(\hat{\theta}_{n}\right)-\theta</p>
<script type="math/tex; mode=display">
如果说估计器$\hat{\theta}_{n}$没有偏差，则$\operatorname{bias}\left(\hat{\theta}_{n}\right)=0$或者说$\mathbb{E}\left(\hat{\theta}_{n}\right)=\theta$，而如果说是偏近无偏的，则是n->∞时，有$\operatorname{bias}\left(\hat{\theta}_{n}\right)=0$或$\mathbb{E}\left(\hat{\theta}_{n}\right)=\theta$。

#### 5.5.3 Variance

我们要考虑的另一个估算器的属性可能是，随着数据样本的变化，我们期望估算器会怎么变化，即方差。表示如下：</script><p>\operatorname{Var}[\hat{\theta}]=\mathbb{E}\left[\hat{\theta}^{2}\right]-\mathbb{E}[\hat{\theta}]^{2}</p>
<script type="math/tex; mode=display">
那么估算器的标准差(standard error(se))可以为：</script><p>\operatorname{se}(\hat{\theta})=\sqrt{\operatorname{Var}[\theta]}</p>
<script type="math/tex; mode=display">

#### 5.5.4 Trading off Bias and Variance and the Mean Squared Error

偏差和方差是估算器错误的两个不同的来源，偏差测量函数与真实值的预期偏差，而方差提供了对任何特定数据采样可能引起的与真实值的偏差的度量。在机器学习中，最常见的折衷方案，通常是通过交叉验证来实现，或者通过计算平均方差(*mean squared error*, MSE):</script><p>\begin{aligned} \mathrm{MSE} &amp;=\mathbb{E}\left[\hat{\theta}_{n}-\theta\right]^{2} \\ &amp;=\operatorname{Bias}\left(\hat{\theta}_{n}\right)^{2}+\operatorname{Var}\left[\hat{\theta}_{n}\right] \end{aligned}</p>
<script type="math/tex; mode=display">
它估计了总体的估计偏差。它们与机器学习的capacity，过拟合，欠拟合都有一定的关系，提高capacity就有可能会增加方差而减小偏差。

### 5.6 Maximum likelihood estimation

这一节讨论先前出现过的那些估算器(**estimators**)的来源：最大似然估计原则。

#### 5.6.2 Regularized Likelihood

在实践中，许多机器学习算法实际上并不适合最大似然算法的框架，而是更通用的框架，在该框架中，除目标函数外，还引入了一个附加项。称为正则化器(**regularizer**)，它取决于所选的函数或参数，表明了对某些函数或参数的偏向。通常，正则化器倾向于更简单的解决方案，例如权重衰减正则化器(**weight decay regularizer**):</script><p>\lambda|\theta|^{2}</p>
<script type="math/tex; mode=display">
其中$\theta\$是参数向量，而$\lambda\$是控制正则化器程度的标量。

### 5.7 Bayesian Statistics

从历史角度来说，统计学可分为正规统计(**orthodox statistics**)和贝叶斯统计(**Bayesian statistics**)，前一种可认为，其真正的参数未知却固定，而其点估计θ是一个随机变量，因为它是一个函数，而后一种贝叶斯的统计，显得更加直接，它使用概率来反映知识状态（即概率代表知识状态的确定性）。 数据是直接观察到的，因此不是随机的。 另一方面，真实参数θ是未知的或不确定的，因此被表示为随机变量。  
在观察到数据之前，使用先验概率$p(\theta)$来表示知识$\theta$，但是通常，先验的分布范围太广了，在观察任何数据之前，其预测的θ值有很高的不确定性。而根据以下公式：</script><p>p(\theta | \boldsymbol{x})=\frac{p(\boldsymbol{x} | \theta) p(\theta)}{p(\boldsymbol{x})}</p>
<script type="math/tex; mode=display">
若能观察到足够的数据，那么得到的先验将获得更少的噪声。

### 5.8 Supervised learning

#### 5.8.1 Estimating Conditional Expectation by Minimizing Squared Error

对于有监督学习来说，目标就是得到一个函数$f$，通过满足以下的方程来得到结果。</script><p>\underset{f}{\arg \min } \mathbb{E}\left[|Y-f(X)|^{2}\right]=\mathbb{E}[Y | X]</p>
<script type="math/tex; mode=display">
注意，方程式中的最小化，覆盖了所有可能的函数f，即，它是一个非参数化的结果。  


### 5.9 Unsupervised learning 

与监督学习不同，无监督学习中没有label或者说target，数据包括了案例集合x，而目标就是学习x的数据结构本身。  

*学习数据的表达形式(**Learning a representation of data**)：*   
一个经典的无监督任务，就是去找到‘最好的’描述数据的方式，通俗点说就是找到一个描述(**representation**)，在遵守一些惩罚或约束的前提下，尽可能的去保留关于x的信息，目标就是使这个描述比x本身更简单或更易于访问。  
比如低阶表达(**Low-dimensional representations**)(尽可能的将关于x的信息压缩到一个更小的描述中)，稀疏表达(**Sparse representations**)(大体上将数据集嵌入一个高阶的描述中，其中非零数很少)，而独立表示(**Independent representations**)试图解开数据分布内部隐含的源的变量，以使表示的尺寸在统计上是独立的。  

#### 5.9.1 Principal Components Analysis

PCA是数据的正交线性变换，将数据投影到元素不相关的表示形式。
![](./读书笔记-Deep-Learning-Bengio/5.5.png)

*密度估算：因子模型(**Density estimation: factor models**)：*   
许多的无监督学习的方法都可以理解为密度估计，其目标是要去(在一系列给定的密度模型中)找到一个密度模型，最能fit给定的数据X，而要找到“最fit”，最常见的方法就是去找到一个密度函数，能最大化数据的可能性，(MLE：Maximum Likelihood Estimation)，而可以将PCA看做是MLE问题的一个结果。

### 5.10 Weakly supervised learning

弱监督学习介于监督学习和非监督学习之间，它假设存在像监督学习里面的x，y数据集对，但是它的y要么是不可靠(缺少值)，要么有噪声(标签不是真实标签)。而在迁移学习范式(transfer learning paradigm)中使用大量易用的弱标记数据，能够帮助解决数据集不够大有噪声的情况。


# Feedforward Deep Networks

### 6.1 Formalizing and Generalizing Neural Networks

前馈神经网络是最早也是最成功的学习算法之一(Rumelhart等人)。它们也称为深度网络，多层感知器（MLP）或简称为神经网络。除了涵盖此类网络的基础知识之外，本章还介绍了通常在条件最大似然准则的情况下的基于梯度优化参数化函数族的一般形式。

(基本流程是先确定函数(parametrized family of functions)，再确定loss函数(loss function)，再确定训练准则和正则化器(training criterion and regularizer)以及优化步骤(optimization procedure))

### 6.2 Parametrizing a Learned Predictor

定义以上四种“工具”的方法有很多，其中最常用的如下：

#### 6.2.1 Family of Functions

多层神经网络的函数族的目的是去组成有效的矩阵转换和非线性转换，如果也选择了正确的参数，那多层神经网络便能从原则上模拟平滑的曲线，如果再加上更多的隐藏层，就能有更好的估计效果。  
其中常见的非线性转换如下：  
> Rectiﬁer or rectiﬁed linear unit (ReLU) or positive part: h(x) = max(0, b+w·x), also written $(b+\boldsymbol{w} \cdot \boldsymbol{x})^{+}$
> Hyperbolic tangent: h(x) = tanh(b+w·x)
> Sigmoid: $h(x)=1 /\left(1+e^{-(b+\boldsymbol{w} \cdot \boldsymbol{x})}\right)$
> Softmax: h(x) = softmax(b+Wx). 它通常用作预测离散概率的非线性输出
> Radial basis function or RBF unit: $h(x)=e^{-\|w-x\|^{2} / \sigma^{2}}$, 这在内核SVM中大量使用，并具有以下优点：可以轻松将这些单元初始化为输入示例的随机子集。
> Softplus: 这是在Dugas等人发明的整流器(rectiﬁer)的平滑版本。
> Hard tanh: 它的形状类似于tanh和整流器，但与后者不同，它是有界的，$h(x)=\max (-1, \min (1, x))$
> Absolute value rectiﬁcation: h(x) = |x|(可用于点乘输出或者tanh单元的输出)。
> Maxout: $h(x)=\max _{i}\left(b_{i}+w_{i} \cdot x\right)$。它概括了整流器，但为每个单元引入了多个权重向量$w_i$（称为滤波器）。

#### 6.2.2 Loss Function and Conditional Log-Likehood

在八九十年代，最常使用的loss函数即使均方误差(squared error): $L\left(f_{\theta}(x), y\right)=\left\|f_{\theta}(x)-y\right\|^{2}$，这告诉神经网络要去学习什么，如果将平方误差替换成绝对值误差，将引导神经网络去预测条件均值，而不是条件预测值。  
然而，当要解决的问题是一个分类问题的时候，像Bernoulli negative log-likelihood这样的方法就会比平方误差更适合一些。而若结果是严格居于0到1之间的连续变量，就需要Sigmoid函数。

##### Softmax

当输出值是离散且非二元的，就建议使用softmax，这项分布由一个N-1项概率值(和为1)组成：</script><p>p=\operatorname{softmax}(a) \Longleftrightarrow p_{i}=\frac{e^{a_{i}}}{\sum_{j} e^{a_{j}}}</p>
<script type="math/tex; mode=display">
其中a = b + Wh是一组分数向量，其中的每一个元素都与一个种类i相联系，那么对应的loss函数就是L(p,y) = - log$p_y$，而降低loss，就会降低非目标类的概率值。

##### Multiple Output Variables

当Y是一个由多个随机变量$Y_1, Y_2,...Y_k$组成时，就必须要选择一个合适的组成它们联合分布的形式，在 X = x 时附有条件，最简单和最普遍的方法就是假设$Y_i$之间彼此条件独立：</script><p>P\left(Y_{1}, Y_{2}, \ldots Y_{k} | x\right)=\prod_{i=1}^{k} P\left(Y_{i} | x\right)</p>
<script type="math/tex; mode=display">
然而一个更常见有力的选择是假设不同的变量$Y_i$，共享一些可以在网络的某些隐藏层中表示的常见元素。

#### 6.2.3 Training Criterion and Regularizer

loss函数告诉我们，我们希望模型去掌握什么，缩小期望的loss，而在实践中，由于我们不知道P（X，Y），而且因为精确地计算和最小化此积分通常是很困难的，所以我们不能最小化此期望。相反，一般基于loss的经验平均值来近似的最小化训练准则(**training criterion**)C(θ)，其中最简单的准则就是平均训练loss：$\frac{1}{n} \sum_{i=1}^{n} L\left(f_{\theta}\left(x_{i}\right), y_{i}\right)$，其中训练集就是一个样本集，然而最好的结果往往是通过cripple模型，不断的防止它轻松的找到最小loss的参数，也就是说我们将数据（训练集平均损失）里的依据与θ可以取的不同值的一些先验偏向相结合（正则化器）。

最常见的正则化器是正则系数λ乘以参数平方范数的附加项$\|\theta\|_{2}^{2}$，这项正则化器通常叫作权重衰减(**weight decay**)或者L2衰减，因为加入平方的L2范数给训练准则后，将推动权重趋向0，与它们的大小成比例。比如，若使用随机梯度下降，用$\frac{\lambda}{2}\|\theta\|^{2}$正则化器每一步的更新将会是：</script><p>\theta \leftarrow \theta-\epsilon \frac{\partial L\left(f_{\theta}(x), y\right)}{\partial \theta}-\epsilon \lambda \theta</p>
<script type="math/tex; mode=display">
其中$\epsilon$是学习速率。

另一个常用的正则化项是L1正则化器，与L1(绝对值)范式成比例，$|\theta|_{1}=\sum_{i}\left|\theta_{i}\right|$，L1正则化器同样偏爱更小值，但是与L2相比，L2权重衰减仅对0而不是较小的值具有较弱的偏好，而L1正则化器会以恒定的梯度继续将参数推向0，即使它们变得非常小，所以它将导致一些参数变得彻底为0。在另一方面，L1正则化器允许部分参数有较大值(相比没有正则化，能相对去除一些大参数)，而L2权重衰减则是惩罚并防止了较大的参数值。另外，L1与L2也可以组合在一起。

#### 6.2.4 Optimization Procedure

确定训练标准后，就进入迭代优化的部分，但如果可能的话，还是想监视模型泛化的性能（例如，验证集的平均损失，通常不包括正则项 ），而不仅仅是训练标准的值。监控在验证集上的性能让我们能在训练迭代的泛化性最佳的那一点上停止训练。


### 6.3 Flow Graphs and Back-Propagation

后项传播一词经常被误解为意味着多层神经网络的整个学习算法，但实际上，它只是用在这些网络中，计算梯度的方法。此外，通常将其理解为对多层神经网络非常特别的东西，但一旦了解了它的规律之后，就可以轻松地将其推广为任意函数（所以说，计算梯度是有意义的)。其中C相对$\theta$的偏导数能告诉我们，为了减少C，$\theta$应该增加还是减少。  
后向传播算法的基础想法就是，cost C相对于参数θ的偏导数, 可以通过将θ与C相关的函数的组成进行递归分解，也就是深度神经网络隐含层的激励函数。

#### 6.3.1 Chain Rule

为了更好的应用后向传播法则，需要充分利用链式法则：</script><p>\frac{\partial C(g(\theta))}{\partial \theta}=\frac{\partial C(g(\theta))}{\partial g(\theta)} \frac{\partial g(\theta)}{\partial \theta}</p>
<script type="math/tex; mode=display">
当然，即使当C，g，$\theta$不是标量而是矢量时，此式同样成立。  
对于标量来说，$\theta$的微小变化能通过求偏导数传递到$g(\theta)$，$g(\theta)$的微小变化也能通过偏导数传递到$C(g(\theta))$。
![](./读书笔记-Deep-Learning-Bengio/6.2.png)
由上图可见，分别用x，y，z代表三个式子，就可很好的解释了。

若g是一个矢量，就可以重写上式：</script><p>\frac{\partial C(g(\theta))}{\partial \theta}=\sum_{i} \frac{\partial C(g(\theta))}{\partial g(\theta)} \frac{\partial g_{i}(\theta)}{\partial \theta}</p>
<script type="math/tex; mode=display">
通过所有中间变量$g_i (\theta)$来对θ对C（g（θ））的影响求和。解释如下
![](./读书笔记-Deep-Learning-Bengio/6.3.png)
其中在x和z之间有两个中间变量$y_1$，$y_2$。

#### 6.3.2 Back-Propagation in a General Flow Graph

更笼统地说，我们可以考虑将函数C（θ）分解为更复杂的计算图，也就是流图(**flow graph**)，图的每个节点$u_i$表示需要通过计算其他节点的值$u_j$，而获得的数值(其中j < i)。节点满足部分顺序，该部分顺序指示计算可以按什么顺序进行。  
接下来将在一个普遍的流图中定义后向传播，使用通用的符号：$u_i = f_i (a_i)$，其中$a_i$是函数$f_i$的各个参数，根据函数值$u_i$的母节点得来：$a_{i}=\left(u_{j}\right)_{j \in \text { mparents }(i)}$，由下图得来：
![](./读书笔记-Deep-Learning-Bengio/6.4.png)

另外，正如下图所示，计算u3到u1的偏导数时，是要计算所有u1对u3的影响，即根据所有路径计算。
![](./读书笔记-Deep-Learning-Bengio/6.5.png)

根据这些理解，我们就能如此定义后项传播算法：
![](./读书笔记-Deep-Learning-Bengio/6.5.1.png)

首先它是在前项传播执行之后再执行，以及它本质上是循环执行的链式法则，通过重新使用已经计算出梯度的子节点i，就能计算出节点j的梯度，由最开始的$\frac{\partial u_{N}}{\partial u_{N}}=1$开始设置输出节点的梯度。  
事实上，这个算法是动态规划法则的应用，以及输出根据任何节点的导数可写为以下形式：</script><p>\frac{\partial u_{N}}{\partial u_{i}}=\sum_{\text {mpaths } u_{1} \cdots u_{k} ; k_{1}=i, k_{n}=N} \prod_{j=2}^{n} \frac{\partial u_{k_j}}{\partial u_{k_{j-1}}</p>
<script type="math/tex; mode=display">
从$u_i$节点到$u_N$节点的所有路径，都是从$u_i$开始，到$u_N$结束，分别相乘，最后再相加就能得到偏导。如上所述，其实求总和很困难，因为可能的路径数量在图的深度上是成指数的。而反向传播算法之所以有效，是因为它采用动态编程策略来重用而不是重新计算与中间节点上的梯度相关的部分和。

### 6.4 Universal Approximation Properties and Depth

当没有隐藏层时，对于凸损失函数和正则化函数（通常是这种情况），我们获得凸训练准则，比如线性回归，逻辑回归，以及其他log-线性的模型，这些模型的运用很广，且由于没有鞍点，没有局部最小值且方便操作，所以很受欢迎，但是它们在表达更复杂的函数时就会遇到限制，比如分类时就会限制在线性决策面，而在实践中，有时候网络不够大，以致于不能提取出足够的特征。

为了让函数更加丰富，就需要一个或更多隐含层，已有论文证明，一个有足够大小和恰当的非线性函数的隐含层能表示任何平滑函数，但是实际上对于更坏的情况，将需要指数型增长的隐含层数目。

深度学习中利用的中心先验之一是可以有效地将要学习的目标函数，表示为更简单函数的深度组合，其中一层的特征可以被重新利用来定义下一层的许多特征，其中网络的层数就是深度(**Depth**)，也就是从一个输入节点到一个输出节点的最长路径的长度，且一贯认为没有隐含层，深度为1，有一个隐含层，深度为2。

### 6.5 Feature / Representation Learning

再次回到诸如感知器，线性回归和逻辑回归的单层网络：此类线性模型之所以吸引人，是因为训练它们涉及凸优化问题，即，具有一定收敛性的优化问题保证了全局最优，不论初始状态如何。在这种情况下，可以使用简单且易于理解的优化算法。但是，这过多地限制了表示能力，并且对于给定的输入表示x（原始输入特征）选择，许多任务无法仅通过使用线性预测变量来解决。为避免这种限制，可以有以下选择：
> 1. 一个选择是内核机器(**kernel machine**)：假设有一个固定映射，从x到$\phi(x)$，其中$\phi(x)$有很高的维度，这时函数$f_{\theta}(x)=b+w \cdot \phi(x)$在参数中能是线性的，以及优化过程依然能是凸的，正是由于kernel策略，只要核$K(u, v)=\phi(u) \cdot \phi(v)$能被有效计算，我们就能从计算上处理一个高阶函数$\phi(x)$(或无限维度)。
> 2. 另一个选择是人工设计特征的表达$\phi(x)$：机器学习的大多数工业应用都依赖于手工设计的特征，并且大多数研发成果（以及机器学习及其应用中的很大一部分科学文献）都用在设计最适合手头任务的新特征。显然，面对要解决的问题和表示形式的某些先验知识（据认为是相关的），先验知识可能非常有用。因此，这种方法在实践中很常见，但并不完全令人满意，因为它是根据任务特别设计的，以及要不断设计更好的特征，来提高系统性能。如果有一些更通用的特征学习方法来应用于大量相关任务（例如与AI相关的任务），那将会更受欢迎。
> 3. 第三个选择是去学习特征，或者说学习表达：从某种意义上讲，它可以在带有通用平滑内核（如RBF SVM和其他非参数统计模型）的内核机器的方法与固定形式的完整设计人员提供的知识之间进行插值完全适合任务的表示形式。这与学习内核的思想相同，只​​是大多数内核学习方法只允许所学习的内核具有很少的自由度，而诸如本书中所讨论的表示学习方法则允许学习内核。


# Optimization for training deep models

在这章中，将大致介绍数值优化--迭代着寻找一个x值，能最大或最小化$f(x)$。

### 8.1 Formalizing and Generalizing Neural Networks

#### 8.1.1 Early Stopping

#### 8.1.2 Plateaus, saddle points, and other flat regions

#### 8.1.3 Cliffs and Exploding Gradients

由于目标函数的二阶结构，就会遇到先前遇到的病态条件和鞍点问题，特别是，目标函数的二阶泰勒级数的逼近过程，产生了一个围绕最小值的对称视图，该视图根据由黑森州矩阵(**Hessian matrix**)的主要特征向量定义的轴进行定向。

而二阶方法和动量或梯度平均方法能够通过调整步长，来解决由于病态条件导致的困难。
![](./读书笔记-Deep-Learning-Bengio/8.1.png)
根据上图，有些方向有较高的坡度(二阶导数)，而有些地方比较平缓，以上的方法都能通过在**valley**的方向增加步长，在陡峭的地方减少步长，减少优化过程的摆动，目标就是平缓的go down，停在谷底。

![](./读书笔记-Deep-Learning-Bengio/8.2.png)
与上图不同，高度非线性的深度神经网络或递归神经网络的损失(**cost function**)通常不是对称的，如图所示，在某些地方存在急剧的非线性，从而在这些地方导致很高的导数。而当参数接近这样的地方时，梯度下降更新可以使参数变换到很远很远的地方，进而破坏很多已经完成的优化工作。

![](./读书笔记-Deep-Learning-Bengio/8.3.png)

如上图所示，不管是从上方靠近“悬崖”，还是从下方靠近“悬崖”都是很危险的，但幸运的是，有一些相当简单的启发式方法可以避免最严重的后果，最简单的，比如限制跳跃的幅度，其实当我们使用梯度来更新参数时，我们应该依赖于无穷小运动的假设。因为不能确保在梯度方向上对参数θ进行有限阶跃将产生改善，而唯一能确保的就是，该方向上足够小的一步是会有用的，从上图可以看出，一个启发式的方法是限制梯度的大小，只有在幅度低于一个阈值(由一个超参数决定)时才保持方向，这能防止在遇到“悬崖”时，跨出有毁灭性的一步。

#### 8.1.4 Vanishing and Exploding Gradients - An Introduction to the Issue of Learning Long-Term Dependencies

对于参数化的系统，比如递归神经网络，有一个特定的优化问题，尤其是在遇到非常深的网络时，那就是梯度爆炸或梯度消失。

**Exploding or Vanishing Product of Jacobians**

关于这个问题的最简单解释是在很深的网络和递归网络之间共享的，这两种情况下，最终输出都是大量非线性变换的组成，即使这些非线性阶段中的每个阶段都可能相对平稳(比如用正弦或者正切函数)，他们的组合都会变得更加非线性，从某种意义上说，整个成分的导数往往会很小或很大，会有更多的起伏。  
比如有这个函数：</script><p>f=f_{T} \circ f_{T-1} \circ \ldots f_{2} \circ f_{1}</p>
<script type="math/tex; mode=display">
它的相对于向量x的导数的雅克比矩阵就是：</script><p>f^{\prime}=f_{T}^{\prime} f_{T-1}^{\prime} \ldots f_{2}^{\prime} f_{1}</p>
<script type="math/tex; mode=display">
其中</script><p>f^{\prime}=\frac{\partial f(x)}{\partial x}</p>
<script type="math/tex; mode=display">
而且</script><p>f_t^{\prime}=\frac{\partial f_t (a_t)}{\partial a_t}</p>
<script type="math/tex; mode=display">
以及</script><p>\boldsymbol{a}_{t}=f_{t-1}\left(f_{t-2}\left(\ldots f_{2}\left(f_{1}(\boldsymbol{x})\right)\right)\right)</p>
<script type="math/tex; mode=display">
组成以及被矩阵乘积代替，如下图中展示：
![](./读书笔记-Deep-Learning-Bengio/8.4.png)  
当组成许多非线性时（例如深度或循环神经网络中的激活非线性），结果是高度非线性的，通常，大多数值与微小的导数相关，某些值与大的导数相关，并且有很多起伏（此处未显示）。在标量的情况下，我们可以想象将多个数字相乘会变得非常大或非常小。而在特殊情况下，在乘积中所有数字均具有相同值α，很明显随着T的增加，如果α<1，则$a^T$变为0，如果α> 1，则$a^T$变为∞。通过取这些数字的对数，将它们视为随机数，并计算这些对数之和的方差，可以理解这些异数的更一般情况。  
显然，尽管可能会发生一些抵消，但方差随T增长，实际上，如果那些数字是独立的，则其随T线性增长，即，总和的大小随$\sqrt{T}$增长，这意味着乘积大致随$e^T$增长。  
若是分析到方阵($spuare matrices$)，可能会有不同的情况，但是在质上，会得到相似的结论，即乘积的大小会以某种方式随着矩阵的数量而增长，并且以指数方式增长。前导特征向量是否对齐好，可以导致一种新的抵消形式。只有在特征值大于1的前导特征向量中，矩阵的乘积才会爆炸。  
然而这些情况是在这些数彼此独立的时候讨论的，在普通的递归神经网络的情况下，这些雅可比矩阵彼此高度相关。每个逐层雅可比行列式实际上是两个矩阵的乘积：递归矩阵W和对角矩阵(其对数是与隐藏单元关联的非线性的导数)，且随时间变化而变化。这使得连续的雅可比行列式具有相似的特征向量，使这些雅可比行列式的乘积爆炸或消失得更快。

**Consequence for Recurrent Networks: Diﬃculty of Learning Long-Term Dependencies**

以上乘积很大或很小的后果就是，使得对长期依赖关系的学习特别困难。    
比如考虑一个相当通用的参数化动态系统，它处理一个输入序列$x_1$, . . . $x_t$, . . . ,：</script><p>s_{t}=F_{\theta}\left(s_{t-1}, x_{t}\right)</p>
<script type="math/tex; mode=display">
其中$s_t$叫作系统的状态，$F_\theta$是递归函数，用于将前一个状态和当前输入映射到下一个状态。而目前的状态可以用来通过输出功能产生输出：</script><p>o_{t}=g_{\omega}\left(s_{t}\right)</p>
<script type="math/tex; mode=display">
并且在每个时间步长上，根据函数$o_t$的输出以及可能的目标$y_t$，计算Loss$L_t$。  
若是考虑在T时刻的，当前函数$F_\theta$的Loss$L_T$的相对于参数$\theta$的导数，就可以将其分解为：</script><p>\frac{\partial L_{T}}{\partial \theta}=\sum_{t \leq T} \frac{\partial L_{T}}{\partial s_{T}} \frac{\partial s_{T}}{\partial s_{t}} \frac{\partial F_{\theta}\left(s_{t-1} x_{t}\right)}{\partial \theta}</p>
<script type="math/tex; mode=display">
其中最后一个雅可比矩阵在计算$F_{\theta}\left(s_{t-1}, x_{t}\right)$时，仅将$\theta$的直接影响作为Fθ的参数，即不考虑$\theta$通过$s_{t-1}$的间接影响。可以注意到，我们能建立一个表，其中$\theta$影响每一个状态$s_{t}$，接而影响$L_{T}$和$s_{T}$，所以现在发现$\frac{\partial s_{T}}{\partial s_{t}}$可以写成</script><p>\frac{\partial s_{T}}{\partial s_{t}}=\frac{\partial s_{T}}{\partial s_{T-1}} \frac{\partial s_{T-1}}{\partial s_{T-2}} \ldots \frac{\partial s_{t+1}}{\partial s_{t}}</p>
<script type="math/tex; mode=display">
可以发现上述方程容易消失或爆炸。  

因此由上面可知，$\frac{\partial L_{T}}{\partial \theta}$是一个从时间T-t的，带有权重的项目和，且权重对于与t的状态与T的状态相关的长期依赖关系来说，呈几何般的过大或过小。 所以为了建造一个能可靠的储存记忆的递归网络，每个状态与下一个状态相关联的雅可比行列式$\frac{\partial s_{t}}{\partial s_{t}-1}$必须具有小于1的行列式。因此，当模型能够捕获长期依存关系时，它也会面对，比如梯度消失，或长期依存关系的权重比总梯度中的短期依存关系的权重呈几何级数地小的情况。不是说不能学习，只是说需要一个非常长的时间来学习长期部分，因为关于这些部分的信号往往会被短期部分引起的最小波动所掩盖。

### 8.2 Optimization algorithms

#### 8.2.1 Approximate Natural Gradient and Second-Order Methods

#### 8.2.2 Optimization strategies and meta-algorithms

#### 8.2.3 Coordinate descent

在有些情况，要快速解决优化问题，可以直接把它分解为单独的部分，可以先只根据$x_i$优化，再根据$x_j$优化等等。这样肯定能到达一个局部的最小值，这也叫做坐标下降(**coordinate descent**)，另外**block coordinate descent**也就是一次同时优化变量的一个子集。  
在优化问题的不同变量能很清晰的被分成不同组，且分别起到不同的作用时，或者优化其中一组会比其他变量更有效时，该方法最有用。  
当然在一个变量的值强烈影响另一个变量的最佳值时，该方法就不那么有效。


# Structured Probabilistic Models: A Deep Learning Perspective

深度学习借鉴了许多建模形式主义，研究人员可以使用它们来指导他们的设计工作和描述他们的算法。这些形式主义之一是结构化概率模型的思想。结构化的概率模型是一种描述概率分布的方法，它使用图形来描述概率分布中的哪些随机变量直接相互影响。在这里，我们使用图论意义上的“图”，即一组由一组边相互连接的顶点。 由于模型的结构由图形定义，因此这些模型通常也称为图形模型。

### 9.1 The Challenge of Unstructured Modeling

深度学习的目标是将机器学习扩展应用到解决人工智能所需的各种挑战上。我们需要的特征空间通常很大，因为我们需要合理地模拟出人和动物通过其各种感觉器官观察到的特征。比如自然图像，就算只是一个小patch，也会有上千特征，就算每个特征是最简单的二元特征，也会比这个宇宙中已知的原子数大得多。  
通常，如果我们希望去对包含n个离散变量（每个变量能够取k个值）的随机向量x的分布进行建模，那么通过最直接的方法，即存储一个查找表来表示P（x）的每个可能结果，就会需要$k^n$参数。  
这从内存(储存模型)，数据效率(为了避免过度拟合，合理的经验法则是，训练样本的数量应比模型中的参数多大约十倍)，运行时间(要遍历每一个表，且上采样也很耗时间)。  
因此，基于表的方法的问题在于，该方法允许变量的每个可能子集之间都能进行各种可能的交互。但我们在实际任务中遇到的概率分布比这要简单得多，通常大多数变量只能间接地相互影响。  
假设团队由三名跑步者由Alice，Bob和Carol组成。比赛开始时，爱丽丝（Alice）随身携带一支接力棒，开始在赛道上奔跑。在赛道上完成圈后，她将接力棒交给了鲍勃。鲍勃然后自己跑一圈，将接力棒交给了最后一圈的卡罗尔。我们可以将每个完成时间建模为一个连续的随机变量。爱丽丝的完成时间不取决于其他人，因为她是第一位的。鲍勃的完成时间取决于爱丽丝，因为鲍勃直到爱丽丝完成比赛才有机会开始自己的圈速。如果爱丽丝（Alice）完成得更快，那么鲍勃（Bob）将会更快地完成，其他所有条件都相同。最后，Carol的完成时间取决于她的两个队友。如果爱丽丝很慢，鲍勃也可能会完成得很晚，而卡罗尔的起步时间会很晚，因此完成时间也可能会很晚。但是，Carol的结束时间仅间接取决于Bob的Alice的结束时间。如果我们已经知道Bob的结束时间，那么我们将无法通过找出Alice的结束时间来更好地估计Carol的结束时间。这意味着我们可以仅使用两个交互对接力竞赛进行建模：爱丽丝对鲍勃的影响和鲍勃对卡罗尔的影响。我们可以从模型中忽略Alice和Carol之间的第三种间接交互。  
所以结构化的概率模型为仅对随机变量之间的直接交互建模提供了正式的框架。这使得模型具有明显更少的参数，而这些参数又可以从更少的数据中可靠地进行估算。更加的减少了成本。

### 9.2 A Graphical Syntax for Describing Model Structure

结构化概率模型使用的图，使用顶点（也称为节点）来表示随机变量。这些图使用节点之间边，来表示随机变量之间的直接交互。图的不同类型为这些边赋予不同的确切含义。

#### 9.2.1 Directed Models

一种结构化的概率模型是有向图模型，也称为信念(**belief**)网络或贝叶斯网络。有向图模型被称为“有向图”，因为它们中的边是有向的，即它们从一个顶点指向另一个顶点。该方向在图中用箭头表示。在有向图模型中，箭头指示哪个变量的概率分布是根据其它变量定义的。如果根据随机变量a的状态定义了随机变量b的概率分布，则我们从a到b绘制箭头。  
如之前的例子，三人的结束时间分别为$t_0$，$t_1$，$t_2$，则$t_1$的结果取决于$t_0$，$t_2$的结果取决于$t_1$，但只间接取决于$t_0$，我们可以画出以下关系。
![](./读书笔记-Deep-Learning-Bengio/9.2.png) 
形式上，在变量x上定义的有向图模型由有向无环图G定义，该无环图的顶点是模型中的随机变量，并且有一组局部条件概率分布(**local conditional probability distributions**)$p\left(\mathbf{x}_{i} | P a_{\mathcal{G}}\left(\mathbf{x}_{i}\right)\right)$，其中$P a_{\mathcal{G}}\left(\mathbf{x}_{i}\right)$是图G中$x_i$的父节点，那么根据x的概率分布可写为：</script><p>p(\mathbf{x})=\Pi_{i} p\left(\mathbf{x}_{i} | P a_{\mathcal{G}}\left(\mathbf{x}_{i}\right)\right)</p>
<script type="math/tex; mode=display">
在接力的例子中，意味着：</script><p>p\left(\mathrm{t}_{0}, \mathrm{t}_{1}, \mathrm{t}_{2}\right)=p\left(\mathrm{t}_{0}\right) p\left(\mathrm{t}_{1} | \mathrm{t}_{0}\right) p\left(\mathrm{t}_{2} | \mathrm{t}_{1}\right)</p>
<script type="math/tex; mode=display">
如果将10分钟按照6秒分成很多块，那么直接列表的结果将是100\*100\*100-1，但是如果是用条件概率分布，那么$t_0$的值有99个，$t_0$到$t_1$的表有9900个值，$t_1$到$t_2$也是，这总共就有19899个值，这意味着使用有向图能减少50倍的参数。  
总的来说，要建模一个有n个离散变量，每个变量有k个值，那么单张表就要$O\left(k^{n}\right)$，那么假设我们现在要基于这些变量，建立一个直接有向图模型，m是单个条件概率分布中变量个数的最大数，那么直接建表的损失就变成$O\left(k^{m}\right)$，只要能设计一个模型满足（m<<n），就能很大程度节省。  
也就是说，只要每个变量在图中都有一些父节点，那么分布就能有很少的参数表示。而图中的一些限制(比如树)，能保证像，在变量的子集上计算边缘或条件概率的操作是有效的。  
需要知道的是，这个表只是记录了哪个变量依赖于哪个变量的信息简化记录了，当然也可以做其他假设，比如三个跑步者之间有其他关系，但是这样就有可能不能被有向图记录关系。

#### 9.2.2 Undirected Models

有向图通常在因果关系只在一个方向上流动的情况下更有意义，所以不是所有的情况都适合有向图模型。比如这个例子：  
有三个二元变量：你是否生病，你的同事是否出生病，你的室友是否生病，现在也可以先做出假设，你的室友和同事不认识，所以他们之间不会彼此直接传染，但是他们会通过传染给你来互相传染，所以他们之间的间接传染的模型可以通过建立同事传染给你再传给室友的模型来建立，如果你的室友感染你和你感染你的室友的可能性一样，那么这就不是一个单纯的单一方向的模型，这就需要另一个模型了。  
无向模型，也可以说马尔可夫随机场（MRFs）或马尔可夫网络，是边没有方向的图形模型，如果两个节点通过一条边连接，则与这些节点相对应的随机变量将直接彼此交互。  
表示你和室友和同事的健康值分别为$h_y$，$h_r$，$h_c$，那么表示该场景的图如下：
![](./读书笔记-Deep-Learning-Bengio/9.3.png) 
事实上，无向图模型就是定义在无向图G上的一个结构概率模型，对于图中的每一个集团C，参数$\phi(\mathcal{C})$，衡量该集团中每个可能处于不同状态的变量之间的亲和力。这些参数被约束为非负的。 它们共同定义了非归一化的概率分布：</script><p>\tilde{p}(\mathbf{x})=\Pi_{\mathcal{C} \in \mathcal{G}} \phi(\mathcal{C})</p>
<script type="math/tex; mode=display">
只要所有集团很小，非标准化概率分布就可以有效地工作。它编码了具有更高亲和力的状态的可能性。但是，与贝叶斯网络不同，集团的定义几乎没有结构，因此无法保证将它们相乘会产生有效的概率分布。

#### 9.2.3 The Partition Function

虽然非归一化分布能保证非负，但是无法保证合为1，所以为了获得有效的概率分布，我们必须获得对应的归一化分布：</script><p>p(\mathbf{x})=\frac{1}{Z} \tilde{p}(\mathbf{x})</p>
<script type="math/tex; mode=display">
其中Z是导致概率合为1的值：</script><p>Z=\int \tilde{p}(\mathbf{x}) d \mathbf{x}</p>
<script type="math/tex; mode=display">
在$\phi$是常数时，你也可以认为Z是常数，所以如果$\phi$函数有参数时，Z也是有这些参数的。在文献中通常写Z时省略其参数以节省空间。而由于Z是状态x的所有可能的联合分配的整数或总和，因此计算通常很困难。 为了能够获得无向模型的归一化概率分布，模型结构和φ函数的定义必须有利于有效地计算Z。而要p(x)存在，Z也必须存在，而Z的一般定义一般无法保证它存在，例如，假设我们要为在单个派系势$φ（x）= x_2$下的单个标量变量x∈R建模。在这种情况下，</script><p>z=\int_{-\infty}^{\infty} x^{2} d x</p>
<script type="math/tex; mode=display">
而有时候$\phi$函数的某些参数的选择可能会决定概率分布的定义，进而决定Z是否存在。  
有向图和无向图的一个重要区别是有向图一开始就直接根据概率分布定义，而无向图先宽松的根据$\phi$函数定义，然后再转向概率分布。

#### 9.2.4 Energy-Based Models

许多有趣的关于无向图的理论结果都是基于一个假设：对于任意的$\mathbf{x}$，都有$\tilde{p}(\mathbf{x}) > 0$，一种方便的解决办法是使用基于能量的模型（EBM）：</script><p>\tilde{p}(\mathbf{x}) = exp(-E(\mathbf{x}))</p>
<script type="math/tex; mode=display">
而$E(x)$即为能量函数(energy function)，因为exp(x)始终大于0，因此可以自由的选择能量函数，这让学习能更简单一些。如果我们之间从clique里面学习，那我们就需要使用一些约束优化，并设置一些特定的最小概率值，但是若通过能量函数学习，我们就能使用非约束优化，而且该模型中的概率值能达到任意接近0但非0的值。任何以上式的形式给出的分布叫作博尔兹曼分布，因此许多基于能量的模型也叫做博尔兹曼机。  
无向图中的cliques对应了非归一化概率函数的参数。而因为$exp(a)exp(b)=exp(a+b)$，这意味着无向图中的不同的cliques对应了能量函数的不同项，也就是说，基于能量的模型只不过是另一种特殊的马尔可夫网络：幂运算使能量函数中的每个项对应于一个不同clique的一个因子。比如下图：
![](./读书笔记-Deep-Learning-Bengio/9.5.png) 
该图说明E(A, B, C, D, E, F)可以写作$E_{A, B}(A, B)+E_{B, C}(B, C)+E_{A, D}(A, D)+E_{B, E}(B, E)+E_{E, F}(E, F)$，注意我们可以通过设置每个$\phi$为对应负能量的指数幂来得到$\phi$函数，即$\phi_{A, B}(A, B)=exp(-E(A, B))$

#### 9.2.5 Separation and D-Separation

图形模型的主要目的是指定在给定的概率分布中哪些相互作用不会发生，以便我们可以节省计算资源并以更高的统计效率估算模型。图中的边缘显示了哪些变量直接交互，但是了解哪些变量间接交互以及在何种情况下交互也是有用的。  
在无向模型的情况下，确定图中的独立性非常简单。在无向模型中，图表所隐含的这种独立性称为分离(**separation**)。我们说如果给定第三组变量S，图表能意味出一组变量A与另一组变量B相独立，则说变量集A，由另一个变量集B中分离出来了。确定出哪些变量是分离的是简单的。如果两个变量A和B由一条仅涉及到未观察变量的路径连接，则这些变量不算分开。如果这些变量无法以这种方式间接相互依赖，则它们是分离的。我们将仅包含未观察变量的路径称为“active”，将包含观察变量的路径称为“inactive”。  
当我们绘制图形时，我们可以通过用阴影标示观察到的变量。同样的概念可以应用到有向图，只不过在有向图里面，叫作d-separation，d指的是独立性。和无向图的定义相同。  
与无向模型一样，我们可以通过查看图中存在哪些 active 路径来检查图所隐含的独立性。如前所述，如果两个变量之间存在 active 路径，则它们是相关的；如果不存在这样的路径，则两个变量是d-separation的。 在有向网中，确定路径是否处于 active 状态会更加复杂。  
事实上，有些分布包含无法用图表的方式来表示。

#### 9.2.7 Factor Graphs

Factor graphs 是绘制无向模型的另一种方法，可以解决标准无向模型语法的图形表示形式中的歧义。在无向模型中，每个φ函数的范围必须是图中某些 clique 的子集。但是，没有必要存在一个φ的范围包含每个集团的整体。Factor graphs 明确表示每个φ函数的范围。具体来说，Factor graphs 是无向模型的图形表示，该模型由两部分无向图组成。一些节点绘制为圆形。这些节点与标准无向模型中的随机变量相对应。其余节点绘制为正方形。这些节点对应于非归一化概率分布的因子。变量和因子可能会用无方向的边连接。当且仅当变量是非归一化概率分布中因子的自变量之一时，变量和因子才在图中连接。不能将任何因子与图中的其他因子相关联，也不能将变量与变量相关联。有关因子图如何解决无向网络解释中的歧义的示例，请参见图9.10。
![](./读书笔记-Deep-Learning-Bengio/9.10.png) 
Factor graph 解决歧义的例子：a）具有多个变量A，B和C的一个 clique 的无向网络。b）对应于同一个无向模型的 Factor graph。该因子图有一个与所有三个变量相关的因子。 c）同一个无向模型的另一个有效因子图。该因子图具有三个因子，每个因子仅涉及两个变量。 请注意，与（b）相比，（c）中的表示，推理和学习都渐近简单，即使两者都需要相同的无向图来表示。

### 9.5 Advantages of Structured Modeling

从由结构化模型定义的概率分布p(x)中提取出样本x是一个很重要的操作。  
从基于能量的模型进行采样并非易事。假设我们有一个基于能量的模型(EBM)，其定义了分布p（a，b）。为了采样a，我们必须从p（a | b）中提取它，并且为了采样b，我们必须从p（b | a）中提取它。这似乎是一个棘手的先有鸡还是先有蛋问题。有向图模型避免了这种情况，因为它们的G是有向的且是非循环的。在祖先采样(从没有父节点的变量开始)中，只需简单地按照拓扑顺序对每个变量进行采样，并以每个变量的父节点为条件，因为这能保证已经对它们进行了采样。这定义了一种有效的单次获取样品的方法。  
在EBM中，事实证明，我们可以通过使用马尔可夫链进行采样来解决这个鸡和鸡蛋的问题。马尔可夫链由状态x和过渡分布$T(x' | x)$定义。运行马尔可夫链意味着重复将状态x更新为从$T(x' | x)$采样的值x。  
在特定分布下，马尔可夫链最终能保证从均衡分布$\pi(x')$中得出x，该均衡分布由条件定义：</script><p>\forall \boldsymbol{x}^{\prime}, \pi\left(\boldsymbol{x}^{\prime}\right)=\sum_{\boldsymbol{x}} T\left(r v x^{\prime} | \boldsymbol{x}\right) \pi(\boldsymbol{x})</p>
<script type="math/tex; mode=display">
可以将$\pi$视为向量（元素中每个可能值x的概率由x，$\pi(x)$索引） 和T为对应的随机矩阵（行索引为$x'$，列索引为x），即，一列的所有元素的非负条目的总和为1。 然后，上式变为：</script><p>T \pi=\pi</p>
<script type="math/tex; mode=display">
一个表示π是特征值1的T的特征向量的特征向量方程。可以证明（Perron-Frobenius定理），这是最大的可能的特征值，并且在温和条件下（例如$T(x' | x) > 0$）唯一值为1的。我们还可以将此方程看作是固定的点方程，用于更新与马尔可夫链的每个步骤相关的分布。如果我们通过选择$x_0$〜$p_0$来开始一条链，则在下一步之后我们得到分布$p_1 = T p_0$，而在t步之后我们得到$p_t = T p_{t-1} = T^t p_0$。 如果此递归收敛（链具有所谓的平稳分布），则它收敛到一个固定点，对于t→∞，该点恰好是$p_t = \pi$，并且动态系统视图符合特征视图。  
此条件保证了此过渡采样过程的重复应用不会改变马尔可夫链状态的分布。运行马尔可夫链直到达到其平衡分布被称为“burning in”马尔可夫链。  
不幸的是，没有理论可以预测马尔可夫链达到平衡分布之前必须走多少步，也没有任何方法可以确定该事件已经发生。同样，即使连续的样本来自相同的分布，它们之间也高度相关，因此要获取多个样本，应该在收集每个样本之间的许多步骤上运行马尔可夫链。几个步骤之后，马尔可夫链趋于卡在π（x）的单一模式中。马尔可夫链从一个模式移动到另一个模式的速度称为其混合速率。由于在马尔可夫链中burning in并使其充分混合可能需要几个采样步骤，因此从EBM正确采样仍然是一个成本较高的过程。

### 9.4 Learning about Dependencies

在这里，我们考虑两种类型的随机变量：观察得到或“可见(visible)”变量v和潜在的或“隐藏(hidden)”变量h。 v对应于训练期间数据集中实际提供的变量。h则包括，为了帮助解释v中的结构而引入模型的变量。通常，h的确切语义取决于模型参数，并由学习算法创建。这样做的动机是双重的。

#### 9.4.1 Latent Variables Versus Structure Learning

通常，v的不同元素高度相互依赖。一个不包含任何潜在变量的v的好模型，会倾向在贝叶斯网络的每个节点上需要有非常多的父节点，或者在马尔科夫网络中有非常大的 cliques。从计算的意义上来说，仅代表这些更高阶的交互的代价是很昂贵的，因为必须存储在内存中的参数数量与 clique 中成员的数量成指数比例，而且在统计意义上也是如此，因为这种指数数量的参数需要大量数据才能准确估算。  
还有一个问题，就是要了解哪些变量需要放在如此庞大的群体中。机器学习中的一大块领域称为结构学习，整个领域都致力于解决这个问题（Koller和Friedman，2009）。大多数结构学习技术都涉及拟合具有特定结构的模型到数据上，并为其分配一定的分数，以奖励较高的训练集准确性并惩罚模型的复杂性，然后贪婪地从图上增加或减去边，来增加得分。  
相反，使用潜在变量可以避免整个问题。可见变量和隐藏变量之间的固定结构可以使用可见单元和隐藏单元之间的直接交互来施加可见单元之间的间接交互。使用简单的参数学习技术，我们可以学习具有固定结构的模型，该模型在边际p（v）上插入正确的结构。  
相反，使用潜在变量可以避免整个问题。一个有可见变量和隐藏变量的固定结构可以使用可见单元和隐藏单元之间的直接交互来施加可见单元之间的间接交互。使用简单的参数学习技术，我们可以学习具有固定结构的模型，以在边际p（v）上插入正确的结构。

#### 9.4.2 Latent Variables for Feature Learning

使用潜在变量的另一个优点是它们通常会发展出有用的语义。如第3.10.5节所述，高斯模型的混合能学习到一个隐变量，对应于从中提取输入的示例类别。具有更多潜在变量的其他更复杂的模型可以创建更丰富的输入描述。

### 9.5 Markov Chain Monte Carlo Methods

### 9.6 Inference and Approximate Inference Over Latent Variables

### 9.7 The Deep Learning Approach to Structured Probabilistic Modeling

深度学习实践者通常使用与其他使用结构化概率模型的机器学习实践者相同的基本计算工具。但是，在深度学习的背景下，我们通常会就如何组合这些工具做出不同的设计决策，从而导致总体算法和模型与传统图形模型相比有很大不同。  
图形模型设计的深度学习风格与图形模型设计的传统风格之间最明显的区别是，深度学习风格大量强调了潜在变量的使用。深度学习模型通常具有比观察到的变量更多的潜在变量。此外，从业者通常不希望潜在变量提前采用任何特定的语义-训练算法可以自由地发明其为特定数据集建模所需的概念。尽管可视化技术可以对它们表示的内容进行一些粗略的描述，但是对于人类来说，潜在变量通常不太容易理解。变量之间的复杂非线性交互是通过流经多个潜在变量的间接连接实现的。相比之下，即使某些训练示例中随机丢失了许多变量，传统的图形模型通常也包含至少偶尔会观察到的变量。变量之间的复杂非线性交互通过使用高阶术语进行建模，并使用结构学习算法来修剪连接和控制模型容量。当使用潜在变量时，它们通常被设计为代表一些具有特定语义的变量，例如文档主题，学生的才智，导致患者症状的疾病等。这些模型通常更容易被人解释。从业人员通常具有更多的理论保证，但无法扩展到复杂的问题，并且无法在与深度模型一样多的不同上下文中重用。  
另一个明显的区别是深度学习方法中通常使用的图结构。这与推理算法的选择紧密相关。图形模型的传统方法通常旨在保持精确推理的可处理性。当此约束过于局限时，一种流行的精确推理算法就是循环信念传播。这两种方法通常都适用于稀疏连接的图。相比之下，很少有有趣的深度模型接受具体的推断，而循环信念传播几乎从未用于深度学习。大多数深度模型的设计都是为了使Gibbs采样或变分推理算法更有效，而不是使循环的信念传播更为有效。另一个考虑因素是，深度学习模型包含大量潜在变量，因此高效的数字代码必不可少。由于这些设计约束，大多数深度学习模型被组织成规则的重复模式，这些单元被分组为层，但是相邻层可能会彼此完全连接。使用稀疏连接时，它们通常遵循常规模式，例如卷积模型中使用的块连接。  
最后，用于图形建模的深度学习方法的特点，在于对未知数的容忍度。与其简化模型直到精确计算出我们可能想要的所有数量，不如增加模型的功能直到几乎不可能训练或使用为止。我们经常使用无法计算其边际分布的模型，并且可以简单地从这些模型中提取近似样本。我们经常用难以解决的目标函数训练模型，以致于无法在合理的时间内进行近似估计，但是如果我们能够有效地获得该函数的梯度估计值，我们仍然能够近似训练模型。深度学习方法通常是确定我们绝对需要的最小信息量，然后确定如何尽快获得该信息的合理估计值。

# Unsupervised and Transfer Learning

尽管监督学习一直是深度学习的主力军，但本书的作者认为，未来发展的关键要素很可能是无监督学习。  
在第1章中，我们介绍了representation的概念，即某些representation比其他representation更有用（例如，分类图像中的对象或语音中的音素）。如此处所述，这建议学习representation，以便以系统的方式“选择”最佳的representation，即优化一个函数，以将原始数据映射到其representation，而不是（或除此以外）手工制作它们。  
但是，如果我们没有带标签的示例怎么办？还是太少？纯粹的没有太多带标签的数据集的监督学习，很容易过拟合。但另一方面，人类（和其他动物）有时可以仅从一个或几个示例中学习一项任务。这是怎么做到的？首先人类必须依靠先前获得的知识，无论是先天获得的知识，还是依靠先前学习经验获得的知识。那我们能否仅从未标记的数据中发现好的representation呢？我们可以将未标记的数据与标记的数据结合起来吗？如果不只有一项任务，而是有许多任务，且可以共享相同的representation或部分representation，那又该怎么办？如果我们既有“训练任务”（有足够的带标签的示例可用）又有“测试任务”（在学习表示representation时不知道，并且仅会提供很少的带标签的示例）怎么办？如果测试任务相似但与训练任务不同怎么办？ （这是迁移学习和领域适应）。 

### 10.1 Auto-Encoders

几十年来，自动编码器一直是神经网络历史发展的一部分，但近年来在加速发展。多年来，它们仍然处于边缘状态，部分原因是对自动编码器的数学解释和几何基础的不完全理解。  
自动编码器只是一个神经网络，试图将其输入复制到输出。自动编码器的体系结构通常分解为以下部分，如图10.1所示：
![](./读书笔记-Deep-Learning-Bengio/10.1.png) 
* 一个输入，x
* 一个编码函数 f
* 一个“code”或内部表示
* 一个解码函数 g
* 一个输出，也叫“重建” r = g(h) = g(f(x))
* 一个损失函数L，计算衡量“重建”函数r在给定输入x后，是否很好重建的一个标准L(r,x)，目标就是缩小在训练集的例子{x}上预期值和输出值的距离。

#### 10.1.1 Regularized Auto-Encoders

预测出结果听起来有点没用：那什么能够防止自动编码器，只是简单的从输入复制到输出呢？在20世纪，这是通过限制自动编码器的结构来实现的，通过限制code h的尺寸小于输入x的尺寸。  
![](./读书笔记-Deep-Learning-Bengio/10.2.png) 
上图展示了两种典型的自动编码器：undercomplete vs overcomplete，两者的表达层h的尺寸分别小于和大于输入x。像PCA一样，早期使用自动编码器的工作会使用undercomplete（即多个层中的瓶颈）来避免学习identity function，而较新的工作则允许overcomplete的表示形式。近年来我们了解到，即使表示undercomplete，也可以通过其他形式的约束或正则化，使自动编码器有意义地捕获输入分布的结构。实际上，一旦意识到自动编码器可以捕获到输入的分布（间接地，而不是作为显式概率函数），你就会发现，它应该需要更多的内存，因为这会增加要捕获的分布的复杂性（以及可用的数据量）：它不应受输入尺寸的限制。尤其是对浅自动编码器，就更是一个问题，因为它只有单个隐藏层（用于代码）。  
除了瓶颈约束之外，还探索了其它的约束或正则化方法，这些方法可以保证自动编码器可以做一些有用的事情，而不仅仅是学习一些琐碎的 identity-like 的函数：
* 表示形式或其衍生形式的稀疏性：即使中间表示具有很高的维数，如果h的大多数元素为零（或任何其他常数，比如$\left\|\frac{\partial h_{i}}{\partial x}\right\|$，接近0），则有效的局部维数（在可能的x中捕获坐标系的自由度数）可能会小得多。当$\left\|\frac{\partial h_{i}}{\partial x}\right\|$接近于零，$h_i$不参与对x中的局部变化进行编码。至少四种类型的“自动编码器”属于这种稀疏表示形式：
    1. 稀疏编码（**Sparse coding**）已经大量的作为一种无监督的特征学习和特征推断机制。 它寻找既稀疏又能通过解码器解释输入的表示形式。通常，没有参数编码器，而是将表示视为一个通过优化获得的自由变量，即特定的推理形式：</script><p>\boldsymbol{h}=f(\boldsymbol{x})=\underset{\boldsymbol{h}}{\arg \min } L(g(\boldsymbol{h}), \boldsymbol{x}))+\lambda \Omega(\boldsymbol{h})</p>
<script type="math/tex; mode=display">
其中L是重建loss，f是非参数编码器，g是参数编码器，$\Omega(\boldsymbol{h}$是稀疏正则化器，且实践中，最小化是可以预测到的。为了达到稀疏的目的，优化的目标函数包括一个当representation具有许多零或接近零值时，能最小化的术语，比如L1：$|\boldsymbol{h}|_{1}=\sum_{i}\left|h_{i}\right|$。
    2.稀疏编码的一个有趣变种，通过优化和参数编码器，从而结合了选择representation的自由。被称为预测稀疏分解（PSD）。
    3.频谱的另一端是稀疏的自动编码器，它与标准的自动编码器架构结合在一起，会导致稀疏性损失，从而导致编码器的输出变得稀疏。除了L1 惩罚之外，还探讨了其他稀疏惩罚，包括Student-t惩罚：
    $$\sum_{i} \log \left(1+\alpha^{2} h_{i}^{2}\right)</script><p>其中（$\alpha h_{i}$有一个Student-t 先验密度）以及KL-散度惩罚：</p>
<pre><code>$$-\sum_{i}\left(t \log h_{i}+(1-t) \log \left(1-h_{i}\right)\right)$$
</code></pre><p>其中对于$h_{i} \in(0,1)$，有一个目标稀疏层次t，通过一个Sigmoid 非线性。<br>    4.收缩自动编码器，显式的惩罚$\left|\frac{\partial \boldsymbol{h}}{\partial \boldsymbol{x}}\right|_{F}^{2}$项，即向量$\frac{\partial h_{i}(\boldsymbol{x})}{\partial \boldsymbol{x}}$的平方范数的总和（每个值指示每个隐藏单元$h_i$对x的变化有多少响应，以及该单元对x的哪个变化方向最敏感，特别是x附近）。 由于这种正则化惩罚，自动编码器被称为收缩，因为从输入x到表示h的映射是收缩的，即在所有方向上都具有小的导数。</p>
<ul>
<li>对注入的噪声的鲁棒性：如果在输入或隐藏单元中注入了噪声，或者有些输入缺失了，而要求神经网络重建干净完整的输入，那么它将不能简单地学习 identify function。它必须捕获数据分布的结构，以便最佳地执行此重构。这种自动编码器称为降噪自动编码器。</li>
<li>先验对represention的压力：一种有趣的将正则化的概念归纳应用representation的方法，是在自动编码器的代价函数中引入对数优先项<script type="math/tex; mode=display">
\log P(\boldsymbol{h})</script>它捕获了以下假设：我们希望找到一种具有简单分布的represention，或者至少要找到一种比原始数据分布更简单的表示形式。在所有编码函数f中，我们想选择一个</li>
</ul>
<ol>
<li>可以（轻松）反转，这是通过最小化一些重建损失来实现的。</li>
<li>产生分布“更简单”的represention h，即，与原始训练分布本身相比，可以用较少的容量捕获它们。</li>
</ol>
<h4 id="10-1-2-Representational-Power-Layer-Size-and-Depth"><a href="#10-1-2-Representational-Power-Layer-Size-and-Depth" class="headerlink" title="10.1.2 Representational Power, Layer Size and Depth"></a>10.1.2 Representational Power, Layer Size and Depth</h4><p>上述的关于自动编码器的描述中，没有任何要求，限制编码器或解码器一定要浅，但是在有关该主题的文献中，大多数训练过的的自动编码器具有单个隐藏层，该隐藏层即是表示层也是code。<br>首先，我们通过单个隐层神经网络的一般通用的逼近能力知道，足够大的隐层可以以给定的精度表示任何函数。这种观察证明了overcomplete的自动编码器：为了表示足够丰富的分布，在中间表示层中可能需要许多隐藏单元。我们还知道，主成分分析（PCA）对应于一个undercomplete的自动编码器，且没有中间非线性，并且PCA只能捕获一组在空间各处方向均相同的变量。<br>其次，还多次报道训练深度神经网络，特别是深度自动编码器（即具有深度编码器和深度解码器）比训练浅层神经网络更加困难。这实际上是，对贪婪的分层无监督预训练过程进行初始工作的动机，如下节所述，通过该过程，我们只需要训练一系列浅层自动编码器即可初始化深层自动编码器。早期研究表明，如果训练得当，这种深层自动编码器会比相应的浅层或线性自动编码器产生更好的压缩效果。正如第14.3节中讨论的那样，更深的架构在某些情况下（在计算和统计方面），会比较浅的体系结构指数性更有效。但是，由于我们可以通过训练和堆叠浅层网络来有效地预训练深层网络，因此考虑单层自动编码器变得很有趣。  </p>
<h4 id="10-1-3-Reconstruction-Distribution"><a href="#10-1-3-Reconstruction-Distribution" class="headerlink" title="10.1.3 Reconstruction Distribution"></a>10.1.3 Reconstruction Distribution</h4><p>当损失L是简单的平方重建误差时，上述“部分”（编码器函数f，解码器函数g，重建损失L）是有意义的，但是在许多情况下，这是不合适的，例如，当x是一个离散变量的向量或当$P(\boldsymbol{x} | \boldsymbol{h})$不能很好地由高斯分布估计时。就像其他类型的神经网络中一样（从前馈神经网络开始），将loss L定义为对某些目标随机变量的负对数可能性(negative log-likelihood)很方便。<br>因此，我们能产生解码函数$g(h)$的意识，来解码$P(\boldsymbol{x} | \boldsymbol{h})$分布。同样的，我们能生成编码函数$f(x)$的意识，如同下图所示。我们用它来捕获这样一个事实，即噪声在representation h的层次注入，现在将其视为潜在变量。这种推论对于可变自动编码器和广义随机网络的发展至关重要。<br><img src="/2019/09/24/读书笔记-Deep-Learning-Bengio/10.3.png" alt=""><br>随机自动编码器的基本方案，其中编码器和解码器都不是简单的函数，而是包含一些噪声注入，这意味着它们的输出可以看作是从分布中采样，$Q(h | x)$用于编码器，$P(x | h)$用于解码器。RBM是一种特殊情况，其中$P = Q$，但通常这两个分布不一定是与唯一联合分布$P(x, h)$兼容的条件分布。</p>
<h3 id="10-2-Linear-Factor-Models"><a href="#10-2-Linear-Factor-Models" class="headerlink" title="10.2 Linear Factor Models"></a>10.2 Linear Factor Models</h3><p>很早就有研究，去发现相互之间具有简单联合分布的解释性因子，并且是在因素和数据之间的关系呈线性关系的情况下首次进行探索的，即，我们假设数据由如下步骤生成。首先，对实际价值因素进行抽样：</p>
<script type="math/tex; mode=display">
\boldsymbol{h} \sim P(\boldsymbol{h})</script><p>然后给定因子，对实值可观察变量进行采样：</p>
<script type="math/tex; mode=display">
\boldsymbol{x}=\boldsymbol{W} \boldsymbol{h}+\boldsymbol{b}+\text { mnoise }</script><p>其中噪声是典型的高斯和对角线。<br>正如下图中所示：<br><img src="/2019/09/24/读书笔记-Deep-Learning-Bengio/10.4.png" alt=""><br>上图是线性因子模型的基本框架，其中我们假设一个观察到的数据向量x是通过一个隐参数h的线性组合而来，再加上噪声。  </p>
<h4 id="10-2-1-Probabilistic-PCA-and-Factor-Analysis"><a href="#10-2-1-Probabilistic-PCA-and-Factor-Analysis" class="headerlink" title="10.2.1 Probabilistic PCA and Factor Analysis"></a>10.2.1 Probabilistic PCA and Factor Analysis</h4><p>概率PCA（主成分分析）和因子分析都是上述两个等式的特例，并且仅在对先验分布和噪声分布进行选择时有所不同。  </p>

      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/24/986-Interval-List-Intersections-LeetCode/" rel="next" title="986. Interval List Intersections-LeetCode">
                <i class="fa fa-chevron-left"></i> 986. Interval List Intersections-LeetCode
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/09/25/474-Ones-and-Zeroes-LeetCode/" rel="prev" title="474. Ones and Zeroes-LeetCode">
                474. Ones and Zeroes-LeetCode <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">29</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">21</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Learning-for-AI"><span class="nav-number">1.</span> <span class="nav-text">Deep Learning for AI</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-Historical-Perspective-and-Neural-Networks"><span class="nav-number">1.0.1.</span> <span class="nav-text">1.3 Historical Perspective and Neural Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-Challenges-for-Future-Research"><span class="nav-number">1.0.2.</span> <span class="nav-text">1.5 Challenges for Future Research</span></a></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#Linear-algebra"><span class="nav-number">2.</span> <span class="nav-text">Linear algebra</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Probalility-and-Information-Theory"><span class="nav-number">3.</span> <span class="nav-text">Probalility and Information Theory</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Numerical-Computation"><span class="nav-number">4.</span> <span class="nav-text">Numerical Computation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Overflow-and-underflow"><span class="nav-number">4.0.1.</span> <span class="nav-text">4.1 Overflow and underflow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-Poor-conditioning"><span class="nav-number">4.0.2.</span> <span class="nav-text">4.2 Poor conditioning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-Gradient-Based-Optimization"><span class="nav-number">4.0.3.</span> <span class="nav-text">4.3 Gradient-Based Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-1-2-Representational-Power-Layer-Size-and-Depth"><span class="nav-number">4.0.3.1.</span> <span class="nav-text">10.1.2 Representational Power, Layer Size and Depth</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-1-3-Reconstruction-Distribution"><span class="nav-number">4.0.3.2.</span> <span class="nav-text">10.1.3 Reconstruction Distribution</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2-Linear-Factor-Models"><span class="nav-number">4.0.4.</span> <span class="nav-text">10.2 Linear Factor Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#10-2-1-Probabilistic-PCA-and-Factor-Analysis"><span class="nav-number">4.0.4.1.</span> <span class="nav-text">10.2.1 Probabilistic PCA and Factor Analysis</span></a></li></ol></li></ol></li></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>










  
  













  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  

  

  


  


  




  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  


  

</body>
</html>
